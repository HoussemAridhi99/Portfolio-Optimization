{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3tLKrqO_06hI",
        "outputId": "9d13f9a1-8928-43e6-d1cc-23863498bbae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wrds\n",
            "  Downloading wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from wrds) (1.5.3)\n",
            "Collecting psycopg2-binary (from wrds)\n",
            "  Downloading psycopg2_binary-2.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.10.1)\n",
            "Collecting sqlalchemy<2 (from wrds)\n",
            "  Downloading SQLAlchemy-1.4.49-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n",
            "Installing collected packages: sqlalchemy, psycopg2-binary, wrds\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.19\n",
            "    Uninstalling SQLAlchemy-2.0.19:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.19\n",
            "Successfully installed psycopg2-binary-2.9.7 sqlalchemy-1.4.49 wrds-3.1.6\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:17\n",
            "🔁 Restarting kernel...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 120511 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-maw61eop\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-maw61eop\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 53e32836ccb314604a61020253705c31770b1c78\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-z_uj6u6y/elegantrl_4c129c6d4a8b4c91b0457ba985c91462\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-z_uj6u6y/elegantrl_4c129c6d4a8b4c91b0457ba985c91462\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 59fe4b4a1cca0a28e8a5fa4fb80eed9b5d472978\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ray[default,tune]<3,>=2\n",
            "  Downloading ray-2.6.2-cp310-cp310-manylinux2014_x86_64.whl (56.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stockstats<0.6,>=0.5\n",
            "  Downloading stockstats-0.5.4-py2.py3-none-any.whl (21 kB)\n",
            "Collecting alpaca-trade-api<4,>=3\n",
            "  Downloading alpaca_trade_api-3.0.2-py3-none-any.whl (34 kB)\n",
            "Collecting pyportfolioopt<2,>=1\n",
            "  Downloading pyportfolioopt-1.5.5-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrds<4,>=3\n",
            "  Using cached wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Collecting yfinance<0.3,>=0.2\n",
            "  Downloading yfinance-0.2.27-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting exchange-calendars<5,>=4\n",
            "  Downloading exchange_calendars-4.2.8-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.4/191.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn<2,>=1\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stable-baselines3[extra]>=2.0.0a5\n",
            "  Downloading stable_baselines3-2.0.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.4/178.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jqdatasdk<2,>=1\n",
            "  Downloading jqdatasdk-1.9.0-py3-none-any.whl (165 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.9/165.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ccxt<4,>=3\n",
            "  Downloading ccxt-3.1.60-py2.py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyfolio<0.10,>=0.9\n",
            "  Downloading pyfolio-0.9.2.tar.gz (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.15)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.28.2)\n",
            "Collecting msgpack==1.0.3\n",
            "  Downloading msgpack-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.7/323.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11,>=9.0\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.11.1\n",
            "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.6.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pandas>=0.18.1\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp==3.8.2\n",
            "  Downloading aiohttp-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<3.0,>=2.0\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<6.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (2022.12.7)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (40.0.1)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (65.6.3)\n",
            "Collecting aiodns>=1.1.1\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting korean-lunar-calendar\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Collecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toolz in /usr/local/lib/python3.10/site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.12.0)\n",
            "Collecting pyluach\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting thriftpy2>=0.3.9\n",
            "  Downloading thriftpy2-0.4.16.tar.gz (643 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.4/643.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymysql>=0.7.6\n",
            "  Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting SQLAlchemy>=1.2.8\n",
            "  Downloading SQLAlchemy-2.0.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=3.2.3\n",
            "  Downloading ipython-8.14.0-py3-none-any.whl (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.7/798.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib>=1.4.0\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=0.14.0\n",
            "  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn>=0.7.1\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cvxpy<2.0.0,>=1.1.19\n",
            "  Downloading cvxpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=7.0\n",
            "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.42.0\n",
            "  Downloading grpcio-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema\n",
            "  Downloading jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf!=3.19.5,>=3.15.3\n",
            "  Downloading protobuf-4.24.0-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0\n",
            "  Downloading gpustat-1.1.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open\n",
            "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prometheus-client>=0.7.1\n",
            "  Downloading prometheus_client-0.17.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv<20.21.1,>=20.0.24\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.6.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=6.0.1\n",
            "  Downloading pyarrow-12.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.1.1\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
            "Collecting gymnasium==0.28.1\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=1.11\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.65.0)\n",
            "Collecting rich\n",
            "  Downloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.6.0\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shimmy[atari]~=0.2.1\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard>=2.9.1\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farama-notifications>=0.0.1\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting typing-extensions>=4.3.0\n",
            "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Collecting jax-jumpy>=1.0.0\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Collecting psycopg2-binary\n",
            "  Using cached psycopg2_binary-2.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Collecting SQLAlchemy>=1.2.8\n",
            "  Using cached SQLAlchemy-1.4.49-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "Collecting lxml>=4.9.1\n",
            "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4>=4.11.1\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.4\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting html5lib>=1.1\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multitasking>=0.0.7\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Collecting requests<3,>2\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozendict>=2.3.4\n",
            "  Downloading frozendict-2.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycares>=4.0.0\n",
            "  Downloading pycares-4.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.15.1)\n",
            "Collecting ecos>=2\n",
            "  Downloading ecos-2.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting osqp>=0.4.1\n",
            "  Downloading osqp-0.6.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scs>=1.1.6\n",
            "  Downloading scs-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas-datareader>=0.2\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-ml-py>=11.450.129\n",
            "  Downloading nvidia_ml_py-12.535.77-py3-none-any.whl (36 kB)\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
            "  Downloading prompt_toolkit-3.0.39-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pygments>=2.4.0\n",
            "  Downloading Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets>=5\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing<3.1,>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.4)\n",
            "Collecting ale-py~=0.8.1\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting greenlet!=0.4.17\n",
            "  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.7/613.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.4\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.40.0)\n",
            "Collecting ply<4.0,>=3.4\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-16.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.27.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs<4,>=2.4\n",
            "  Downloading platformdirs-3.10.0-py3-none-any.whl (17 kB)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym-notices>=0.0.4\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting swig==4.*\n",
            "  Using cached swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "Collecting box2d-py==2.3.5\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonschema-specifications>=2023.03.6\n",
            "  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
            "Collecting referencing>=0.28.4\n",
            "  Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\n",
            "Collecting rpds-py>=0.7.1\n",
            "  Downloading rpds_py-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core<3.0.0,>=1.0.0\n",
            "  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources\n",
            "  Downloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
            "Collecting wcwidth>=0.1.4\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.21)\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting parso<0.9.0,>=0.8.3\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting qdldl\n",
            "  Downloading qdldl-0.1.7.post0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'aiohttp' candidate (version 3.8.2 at https://files.pythonhosted.org/packages/8f/52/ea1e5eac3e748a94fdaafba5ab68adfb833f0cbdb68cc8149fbba5574176/aiohttp-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/aiohttp/) (requires-python:>=3.6))\n",
            "Reason for being yanked: This version includes overly restrictive multidict upper boundary disallowing multidict v6+. The previous patch version didn't have that and this is now causing dependency resolution problems for the users who have an \"incompatible\" version pinned. This is not really necessary anymore and will be addressed in the next release v3.8.3\n",
            "\n",
            "https://github.com/aio-libs/aiohttp/pull/6950\u001b[0m\u001b[33m\n",
            "\u001b[0mBuilding wheels for collected packages: finrl, pyfolio, elegantrl, empyrical, gpustat, thriftpy2, gym, box2d-py, AutoROM.accept-rom-license, lit\n",
            "  Building wheel for finrl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.6-py3-none-any.whl size=4669336 sha256=46612b5ff10ece41750838a4e4194289b2a5480866d810530a9e65d3f8cf50ef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i7vr8yrg/wheels/72/3b/1a/0fc805a8cc65ecd5bfe4f74a3c586b6075678b8ba53fd8f749\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88663 sha256=8f20e766b1ecfafa7c46acea2345848ba18023bf1b6a3b8138a29d1ed9fe306c\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/38/bc/e53700cfd8b0ad6b539d2fbaaf060ed8a299e7622a5b86ef42\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=elegantrl-0.3.6-py3-none-any.whl size=197329 sha256=0d709c94fc5bec6ef71baf040c854c170a2378eedc2d9a712b0af06678ff95d6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i7vr8yrg/wheels/c0/51/a5/b05f165548221bc570f7223babd33e2992fa873cdcebe2d229\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39762 sha256=35173c1883145e34b7f1c5d9de2ea1126788721df5736fbef9a35c9abaf4fbcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/2e/f2/d6d2d9a1eb8fbbd9949bb5d4c00f753e3b74e5bd7ed10b1d36\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1-py3-none-any.whl size=26274 sha256=02eac7def48b0ca19f83b5a2bd15dd63661fc90b00371799eafa28a84314c32a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/d0/2c/1e02440645c2318ba03aea99993a44a9108dc8f74de0bd370b\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.16-cp310-cp310-linux_x86_64.whl size=511350 sha256=cc64262252443a745dcec5994f601bf26a15b85b5b222b5856c00bd746603c57\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/f5/1d/fe404692e1c8aaea45220c322d1d0f32c9fd40eb0e2bdd571e\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827620 sha256=6f38ab42854485827b5034e8a778390d9b6d06f69838dc28da8ef9ab0c8b8857\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=495284 sha256=21288427ccdc965d74d9d527742fb1f23fe93c62a8a2addb5f880331b89a68d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=e518bc9cb5c1125837956bf9029b2dca1552dd70241681257a01d12d586465da\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93583 sha256=c0faec22c9762bad308ae5e4c52f9aa044273bf59c4c5de44d33400dafb24452\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/f9/07/bb2308587bc2f57158f905a2325f6a89a2befa7437b2d7e137\n",
            "Successfully built finrl pyfolio elegantrl empyrical gpustat thriftpy2 gym box2d-py AutoROM.accept-rom-license lit\n",
            "Installing collected packages: webencodings, wcwidth, swig, pytz, py-spy, pure-eval, ptyprocess, ply, pickleshare, opencensus-context, nvidia-ml-py, multitasking, msgpack, mpmath, lit, korean-lunar-calendar, gym-notices, farama-notifications, executing, distlib, colorful, cmake, box2d-py, backcall, appdirs, websockets, websocket-client, tzdata, typing-extensions, traitlets, threadpoolctl, tensorboard-data-server, sympy, soupsieve, smart-open, six, rpds-py, PyYAML, pyparsing, pymysql, pyluach, pygments, pygame, pyasn1, psycopg2-binary, psutil, protobuf, prompt-toolkit, prometheus-client, platformdirs, pillow, pexpect, parso, packaging, oauthlib, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, multidict, mdurl, MarkupSafe, markdown, lxml, kiwisolver, joblib, importlib-resources, grpcio, greenlet, frozenlist, frozendict, fonttools, filelock, decorator, cycler, cloudpickle, click, charset-normalizer, cachetools, attrs, async-timeout, absl-py, yarl, werkzeug, virtualenv, thriftpy2, tensorboardX, SQLAlchemy, scipy, rsa, requests, referencing, python-dateutil, pydantic, pycares, pyasn1-modules, pyarrow, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, matplotlib-inline, markdown-it-py, jinja2, jedi, jax-jumpy, html5lib, gym, googleapis-common-protos, deprecation, contourpy, blessed, beautifulsoup4, asttokens, ale-py, aiosignal, stack-data, scs, scikit-learn, rich, requests-oauthlib, qdldl, pandas, matplotlib, jsonschema-specifications, gymnasium, gpustat, google-auth, ecos, AutoROM.accept-rom-license, autorom, aiohttp, aiodns, yfinance, wrds, stockstats, shimmy, seaborn, pandas-datareader, osqp, jsonschema, jqdatasdk, ipython, google-auth-oauthlib, google-api-core, exchange-calendars, ccxt, alpaca-trade-api, aiohttp-cors, tensorboard, ray, opencensus, empyrical, cvxpy, pyportfolioopt, pyfolio, triton, torch, stable-baselines3, elegantrl, finrl\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.1.0\n",
            "    Uninstalling charset-normalizer-3.1.0:\n",
            "      Successfully uninstalled charset-normalizer-3.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.28.2\n",
            "    Uninstalling requests-2.28.2:\n",
            "      Successfully uninstalled requests-2.28.2\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 MarkupSafe-2.1.3 PyYAML-6.0 SQLAlchemy-1.4.49 absl-py-1.4.0 aiodns-3.0.0 aiohttp-3.8.2 aiohttp-cors-0.7.0 aiosignal-1.3.1 ale-py-0.8.1 alpaca-trade-api-3.0.2 appdirs-1.4.4 asttokens-2.2.1 async-timeout-4.0.2 attrs-23.1.0 autorom-0.6.1 backcall-0.2.0 beautifulsoup4-4.12.2 blessed-1.20.0 box2d-py-2.3.5 cachetools-5.3.1 ccxt-3.1.60 charset-normalizer-2.1.1 click-8.1.6 cloudpickle-2.2.1 cmake-3.27.1 colorful-0.5.5 contourpy-1.1.0 cvxpy-1.3.2 cycler-0.11.0 decorator-5.1.1 deprecation-2.1.0 distlib-0.3.7 ecos-2.0.12 elegantrl-0.3.6 empyrical-0.5.5 exchange-calendars-4.2.8 executing-1.2.0 farama-notifications-0.0.4 filelock-3.12.2 finrl-0.3.6 fonttools-4.42.0 frozendict-2.3.8 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-1.0.0 googleapis-common-protos-1.60.0 gpustat-1.1 greenlet-2.0.2 grpcio-1.56.2 gym-0.26.2 gym-notices-0.0.8 gymnasium-0.28.1 html5lib-1.1 importlib-resources-6.0.1 ipython-8.14.0 jax-jumpy-1.0.0 jedi-0.19.0 jinja2-3.1.2 joblib-1.3.2 jqdatasdk-1.9.0 jsonschema-4.19.0 jsonschema-specifications-2023.7.1 kiwisolver-1.4.4 korean-lunar-calendar-0.3.1 lit-16.0.6 lxml-4.9.3 markdown-3.4.4 markdown-it-py-3.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.0.3 multidict-5.2.0 multitasking-0.0.11 networkx-3.1 numpy-1.25.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-ml-py-12.535.77 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 oauthlib-3.2.2 opencensus-0.11.2 opencensus-context-0.1.3 opencv-python-4.8.0.76 osqp-0.6.3 packaging-23.1 pandas-2.0.3 pandas-datareader-0.10.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-10.0.0 platformdirs-3.10.0 ply-3.11 prometheus-client-0.17.1 prompt-toolkit-3.0.39 protobuf-4.24.0 psutil-5.9.5 psycopg2-binary-2.9.7 ptyprocess-0.7.0 pure-eval-0.2.2 py-spy-0.3.14 pyarrow-12.0.1 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pydantic-1.10.12 pyfolio-0.9.2 pygame-2.1.0 pygments-2.16.1 pyluach-2.2.0 pymysql-1.1.0 pyparsing-3.0.9 pyportfolioopt-1.5.5 python-dateutil-2.8.2 pytz-2023.3 qdldl-0.1.7.post0 ray-2.6.2 referencing-0.30.2 requests-2.31.0 requests-oauthlib-1.3.1 rich-13.5.2 rpds-py-0.9.2 rsa-4.9 scikit-learn-1.3.0 scipy-1.11.1 scs-3.2.3 seaborn-0.12.2 shimmy-0.2.1 six-1.16.0 smart-open-6.3.0 soupsieve-2.4.1 stable-baselines3-2.0.0 stack-data-0.6.2 stockstats-0.5.4 swig-4.1.1 sympy-1.12 tensorboard-2.14.0 tensorboard-data-server-0.7.1 tensorboardX-2.6.2 threadpoolctl-3.2.0 thriftpy2-0.4.16 torch-2.0.1 traitlets-5.9.0 triton-2.0.0 typing-extensions-4.7.1 tzdata-2023.3 virtualenv-20.21.0 wcwidth-0.2.6 webencodings-0.5.1 websocket-client-1.6.1 websockets-10.4 werkzeug-2.3.6 wrds-3.1.6 yarl-1.9.2 yfinance-0.2.27\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "google",
                  "kiwisolver",
                  "matplotlib_inline",
                  "pexpect",
                  "pickleshare",
                  "prompt_toolkit",
                  "psutil",
                  "six",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "## installer finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "%matplotlib inline\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "from finrl.meta.data_processors.processor_yahoofinance import YahooFinanceProcessor\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")"
      ],
      "metadata": {
        "id": "Jv6o6i7Eey6r"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation des dossiers\n",
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "metadata": {
        "id": "fJkPqx28fBc9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Telechargement des données\n",
        "print(config_tickers.DOW_30_TICKER)\n",
        "df = YahooDownloader(start_date = '2010-01-01',\n",
        "                     end_date = '2023-07-31',\n",
        "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7EUIzghfvm7",
        "outputId": "bf42e0ee-3752-4217-f977-5dc3c3fa7f04"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (100133, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cYKGdSiNv4Fs",
        "outputId": "cb5fc309-0243-4ec6-d36a-0de007b5f000"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2010-01-04   7.622500   7.660714   7.585000   6.572423  493729600  AAPL   \n",
              "1  2010-01-04  56.630001  57.869999  56.560001  45.356094    5277400  AMGN   \n",
              "2  2010-01-04  40.810001  41.099998  40.389999  34.145290    6894300   AXP   \n",
              "3  2010-01-04  55.720001  56.389999  54.799999  43.441975    6186700    BA   \n",
              "4  2010-01-04  57.650002  59.189999  57.509998  41.308014    7325600   CAT   \n",
              "\n",
              "   day  \n",
              "0    0  \n",
              "1    0  \n",
              "2    0  \n",
              "3    0  \n",
              "4    0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-40010b10-53bd-4c16-9861-6492aa080d42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>7.622500</td>\n",
              "      <td>7.660714</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.572423</td>\n",
              "      <td>493729600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>56.630001</td>\n",
              "      <td>57.869999</td>\n",
              "      <td>56.560001</td>\n",
              "      <td>45.356094</td>\n",
              "      <td>5277400</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>34.145290</td>\n",
              "      <td>6894300</td>\n",
              "      <td>AXP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>55.720001</td>\n",
              "      <td>56.389999</td>\n",
              "      <td>54.799999</td>\n",
              "      <td>43.441975</td>\n",
              "      <td>6186700</td>\n",
              "      <td>BA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>59.189999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>41.308014</td>\n",
              "      <td>7325600</td>\n",
              "      <td>CAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40010b10-53bd-4c16-9861-6492aa080d42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-cda6f662-843a-434c-93d6-59f306b11568\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cda6f662-843a-434c-93d6-59f306b11568')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-cda6f662-843a-434c-93d6-59f306b11568 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40010b10-53bd-4c16-9861-6492aa080d42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40010b10-53bd-4c16-9861-6492aa080d42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    use_turbulence=False,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "df = fe.preprocess_data(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7SR6AclQnUC",
        "outputId": "6c7513f5-16f6-491f-d54e-373b61fbfa09"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wMNj9lfxo10i",
        "outputId": "c5a7f6df-5f3e-46aa-e4df-05d538e55f57"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             date       open       high        low      close     volume  \\\n",
              "0      2010-01-04   7.622500   7.660714   7.585000   6.572423  493729600   \n",
              "3415   2010-01-04  56.630001  57.869999  56.560001  45.356094    5277400   \n",
              "6830   2010-01-04  40.810001  41.099998  40.389999  34.145290    6894300   \n",
              "10245  2010-01-04  55.720001  56.389999  54.799999  43.441975    6186700   \n",
              "13660  2010-01-04  57.650002  59.189999  57.509998  41.308014    7325600   \n",
              "\n",
              "        tic  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
              "0      AAPL    0   0.0  6.594175  6.562035   100.0  66.666667  100.0   \n",
              "3415   AMGN    0   0.0  6.594175  6.562035   100.0  66.666667  100.0   \n",
              "6830    AXP    0   0.0  6.594175  6.562035   100.0  66.666667  100.0   \n",
              "10245    BA    0   0.0  6.594175  6.562035   100.0  66.666667  100.0   \n",
              "13660   CAT    0   0.0  6.594175  6.562035   100.0  66.666667  100.0   \n",
              "\n",
              "       close_30_sma  close_60_sma  \n",
              "0          6.572423      6.572423  \n",
              "3415      45.356094     45.356094  \n",
              "6830      34.145290     34.145290  \n",
              "10245     43.441975     43.441975  \n",
              "13660     41.308014     41.308014  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-4ab62443-b40f-4d2d-9066-eb0aa5765195\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>7.622500</td>\n",
              "      <td>7.660714</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.572423</td>\n",
              "      <td>493729600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.594175</td>\n",
              "      <td>6.562035</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.572423</td>\n",
              "      <td>6.572423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>56.630001</td>\n",
              "      <td>57.869999</td>\n",
              "      <td>56.560001</td>\n",
              "      <td>45.356094</td>\n",
              "      <td>5277400</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.594175</td>\n",
              "      <td>6.562035</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>45.356094</td>\n",
              "      <td>45.356094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6830</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>34.145290</td>\n",
              "      <td>6894300</td>\n",
              "      <td>AXP</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.594175</td>\n",
              "      <td>6.562035</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>34.145290</td>\n",
              "      <td>34.145290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10245</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>55.720001</td>\n",
              "      <td>56.389999</td>\n",
              "      <td>54.799999</td>\n",
              "      <td>43.441975</td>\n",
              "      <td>6186700</td>\n",
              "      <td>BA</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.594175</td>\n",
              "      <td>6.562035</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>43.441975</td>\n",
              "      <td>43.441975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13660</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>59.189999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>41.308014</td>\n",
              "      <td>7325600</td>\n",
              "      <td>CAT</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.594175</td>\n",
              "      <td>6.562035</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>41.308014</td>\n",
              "      <td>41.308014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ab62443-b40f-4d2d-9066-eb0aa5765195')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-aa8f4eff-cdec-4d7c-8fb9-28844074f649\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa8f4eff-cdec-4d7c-8fb9-28844074f649')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-aa8f4eff-cdec-4d7c-8fb9-28844074f649 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ab62443-b40f-4d2d-9066-eb0aa5765195 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ab62443-b40f-4d2d-9066-eb0aa5765195');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ajout des matrices de covariance en tant que states\n",
        "df=df.sort_values(['date','tic'],ignore_index=True)\n",
        "df.index = df.date.factorize()[0]\n",
        "\n",
        "cov_list = []\n",
        "return_list = []\n",
        "\n",
        "# look back is one year\n",
        "lookback=252\n",
        "for i in range(lookback,len(df.index.unique())):\n",
        "  data_lookback = df.loc[i-lookback:i,:]\n",
        "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
        "  return_lookback = price_lookback.pct_change().dropna()\n",
        "  return_list.append(return_lookback)\n",
        "\n",
        "  covs = return_lookback.cov().values\n",
        "  cov_list.append(covs)\n",
        "\n",
        "\n",
        "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "df = df.merge(df_cov, on='date')\n",
        "df = df.sort_values(['date','tic']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "69ExcTS9pEoS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decomposition des données\n",
        "train = data_split(df, '2010-01-01','2021-08-01')"
      ],
      "metadata": {
        "id": "egEZs_vppz9q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creation de l'env\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "\n",
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"A single stock trading environment for OpenAI gym\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            input data\n",
        "        stock_dim : int\n",
        "            number of unique stocks\n",
        "        hmax : int\n",
        "            maximum number of shares to trade\n",
        "        initial_amount : int\n",
        "            start money\n",
        "        transaction_cost_pct: float\n",
        "            transaction cost percentage per trade\n",
        "        reward_scaling: float\n",
        "            scaling factor for reward, good for training\n",
        "        state_space: int\n",
        "            the dimension of input features\n",
        "        action_space: int\n",
        "            equals stock dimension\n",
        "        tech_indicator_list: list\n",
        "            a list of technical indicator names\n",
        "        turbulence_threshold: int\n",
        "            a threshold to control risk aversion\n",
        "        day: int\n",
        "            an increment number to control date\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    _sell_stock()\n",
        "        perform sell action based on the sign of the action\n",
        "    _buy_stock()\n",
        "        perform buy action based on the sign of the action\n",
        "    step()\n",
        "        at each step the agent will return actions, then\n",
        "        we will calculate the reward, and return the next observation.\n",
        "    reset()\n",
        "        reset the environment\n",
        "    render()\n",
        "        use render to return other functions\n",
        "    save_asset_memory()\n",
        "        return account value at each time step\n",
        "    save_action_memory()\n",
        "        return actions/positions at each time step\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self,\n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day = 0):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct =transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "\n",
        "        # action_space normalization and shape is self.stock_dim\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
        "        # Shape = (34, 30)\n",
        "        # covariance matrix + technical indicators\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
        "\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.terminal = False\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "        self.portfolio_value = self.initial_amount\n",
        "\n",
        "        # memorize portfolio value each step\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        # memorize portfolio return each step\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['daily_return']\n",
        "            plt.plot(df.daily_return.cumsum(),'r')\n",
        "            plt.savefig('results/cumulative_reward.png')\n",
        "            plt.close()\n",
        "\n",
        "            plt.plot(self.portfolio_return_memory,'r')\n",
        "            plt.savefig('results/rewards.png')\n",
        "            plt.close()\n",
        "\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_daily_return.columns = ['daily_return']\n",
        "            if df_daily_return['daily_return'].std() !=0:\n",
        "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
        "                       df_daily_return['daily_return'].std()\n",
        "              print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "\n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            #print(\"Model actions: \",actions)\n",
        "            # actions are the portfolio weight\n",
        "            # normalize to sum of 1\n",
        "            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
        "            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
        "            #else:\n",
        "            #  norm_actions = actions\n",
        "            weights = self.softmax_normalization(actions)\n",
        "            #print(\"Normalized actions: \", weights)\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            #print(self.state)\n",
        "            # calcualte portfolio return\n",
        "            # individual stocks' return * weight\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            # update portfolio value\n",
        "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])\n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "\n",
        "            # the reward is the new portfolio value or end portfolo value\n",
        "            self.reward = new_portfolio_value\n",
        "            #print(\"Step reward: \", self.reward)\n",
        "            #self.reward = self.reward*self.reward_scaling\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        #self.cost = 0\n",
        "        #self.trades = 0\n",
        "        self.terminal = False\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        #print(len(date_list))\n",
        "        #print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs"
      ],
      "metadata": {
        "id": "ADyNT0AiqJOJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_dimension = len(train['tic'].unique())\n",
        "state_space = stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjgF48o3rjhC",
        "outputId": "d810d971-1a91-4bf3-e986-20b244130d4e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 29, State Space: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"transaction_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": config.INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "\n",
        "}\n",
        "\n",
        "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
        "env_train, _ = e_train_gym.get_sb_env()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GPY-W8yrw8W",
        "outputId": "187a276a-5111-4dd5-ee96-155f2092408e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementation des algorithmes de RL\n",
        "agent = DRLAgent(env = env_train)"
      ],
      "metadata": {
        "id": "cTxQY58Dyzqe"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A2C\n",
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\n",
        "trained_a2c = agent.train_model(model=model_a2c,\n",
        "                                tb_log_name='a2c',\n",
        "                                total_timesteps=200000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBKDRNBQzHkH",
        "outputId": "f90ecc43-ba4d-4ae7-c1ee-917fff4e9f00"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 184       |\n",
            "|    iterations         | 10600     |\n",
            "|    time_elapsed       | 287       |\n",
            "|    total_timesteps    | 53000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10599     |\n",
            "|    policy_loss        | 4.64e+08  |\n",
            "|    reward             | 4115091.0 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 1.8e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5244722.821504814\n",
            "Sharpe:  1.0088676123518703\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 10700     |\n",
            "|    time_elapsed       | 291       |\n",
            "|    total_timesteps    | 53500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10699     |\n",
            "|    policy_loss        | 1.33e+08  |\n",
            "|    reward             | 1121388.9 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 1.31e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 10800     |\n",
            "|    time_elapsed       | 294       |\n",
            "|    total_timesteps    | 54000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10799     |\n",
            "|    policy_loss        | 2.13e+08  |\n",
            "|    reward             | 1756919.6 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 3.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 10900     |\n",
            "|    time_elapsed       | 297       |\n",
            "|    total_timesteps    | 54500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 3.58e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10899     |\n",
            "|    policy_loss        | 2.47e+08  |\n",
            "|    reward             | 2141232.8 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 5.26e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 11000     |\n",
            "|    time_elapsed       | 301       |\n",
            "|    total_timesteps    | 55000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10999     |\n",
            "|    policy_loss        | 3.68e+08  |\n",
            "|    reward             | 3171742.2 |\n",
            "|    std                | 0.958     |\n",
            "|    value_loss         | 1.08e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 11100     |\n",
            "|    time_elapsed       | 303       |\n",
            "|    total_timesteps    | 55500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11099     |\n",
            "|    policy_loss        | 4.87e+08  |\n",
            "|    reward             | 4231255.5 |\n",
            "|    std                | 0.958     |\n",
            "|    value_loss         | 1.87e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5576375.014943824\n",
            "Sharpe:  1.0456534702867877\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 11200     |\n",
            "|    time_elapsed       | 306       |\n",
            "|    total_timesteps    | 56000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11199     |\n",
            "|    policy_loss        | 1.2e+08   |\n",
            "|    reward             | 1066299.9 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 1.24e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 11300     |\n",
            "|    time_elapsed       | 308       |\n",
            "|    total_timesteps    | 56500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11299     |\n",
            "|    policy_loss        | 1.91e+08  |\n",
            "|    reward             | 1615603.5 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 2.66e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 311       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 2.52e+08  |\n",
            "|    reward             | 2206508.5 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 4.98e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 313       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 3.28e+08  |\n",
            "|    reward             | 2703325.5 |\n",
            "|    std                | 0.955     |\n",
            "|    value_loss         | 7.82e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 11600     |\n",
            "|    time_elapsed       | 317       |\n",
            "|    total_timesteps    | 58000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11599     |\n",
            "|    policy_loss        | 4.6e+08   |\n",
            "|    reward             | 3800158.0 |\n",
            "|    std                | 0.955     |\n",
            "|    value_loss         | 1.6e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 11700     |\n",
            "|    time_elapsed       | 320       |\n",
            "|    total_timesteps    | 58500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11699     |\n",
            "|    policy_loss        | 6.37e+08  |\n",
            "|    reward             | 5171006.5 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 2.89e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5366353.362886348\n",
            "Sharpe:  1.0195730649113848\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 324       |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | 1.57e+08  |\n",
            "|    reward             | 1312074.2 |\n",
            "|    std                | 0.953     |\n",
            "|    value_loss         | 1.86e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 11900     |\n",
            "|    time_elapsed       | 326       |\n",
            "|    total_timesteps    | 59500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11899     |\n",
            "|    policy_loss        | 2.35e+08  |\n",
            "|    reward             | 1940083.5 |\n",
            "|    std                | 0.953     |\n",
            "|    value_loss         | 4.02e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 12000     |\n",
            "|    time_elapsed       | 328       |\n",
            "|    total_timesteps    | 60000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11999     |\n",
            "|    policy_loss        | 2.63e+08  |\n",
            "|    reward             | 2400139.2 |\n",
            "|    std                | 0.952     |\n",
            "|    value_loss         | 6.19e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 12100     |\n",
            "|    time_elapsed       | 330       |\n",
            "|    total_timesteps    | 60500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12099     |\n",
            "|    policy_loss        | 4.11e+08  |\n",
            "|    reward             | 3738307.8 |\n",
            "|    std                | 0.952     |\n",
            "|    value_loss         | 1.47e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 183       |\n",
            "|    iterations         | 12200     |\n",
            "|    time_elapsed       | 333       |\n",
            "|    total_timesteps    | 61000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12199     |\n",
            "|    policy_loss        | 5.53e+08  |\n",
            "|    reward             | 4615162.0 |\n",
            "|    std                | 0.952     |\n",
            "|    value_loss         | 2.4e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5793715.6133800065\n",
            "Sharpe:  1.062861117849212\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 12300     |\n",
            "|    time_elapsed       | 336       |\n",
            "|    total_timesteps    | 61500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12299     |\n",
            "|    policy_loss        | 1.35e+08  |\n",
            "|    reward             | 1171198.2 |\n",
            "|    std                | 0.951     |\n",
            "|    value_loss         | 1.41e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 12400     |\n",
            "|    time_elapsed       | 339       |\n",
            "|    total_timesteps    | 62000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12399     |\n",
            "|    policy_loss        | 1.99e+08  |\n",
            "|    reward             | 1685628.5 |\n",
            "|    std                | 0.951     |\n",
            "|    value_loss         | 3.16e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 12500     |\n",
            "|    time_elapsed       | 343       |\n",
            "|    total_timesteps    | 62500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12499     |\n",
            "|    policy_loss        | 2.47e+08  |\n",
            "|    reward             | 2027655.4 |\n",
            "|    std                | 0.951     |\n",
            "|    value_loss         | 4.43e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 12600     |\n",
            "|    time_elapsed       | 346       |\n",
            "|    total_timesteps    | 63000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12599     |\n",
            "|    policy_loss        | 4.04e+08  |\n",
            "|    reward             | 3415326.2 |\n",
            "|    std                | 0.95      |\n",
            "|    value_loss         | 1.17e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 12700     |\n",
            "|    time_elapsed       | 348       |\n",
            "|    total_timesteps    | 63500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12699     |\n",
            "|    policy_loss        | 4.94e+08  |\n",
            "|    reward             | 4401741.5 |\n",
            "|    std                | 0.95      |\n",
            "|    value_loss         | 1.99e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5590087.88419235\n",
            "Sharpe:  1.0508135066398374\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 182        |\n",
            "|    iterations         | 12800      |\n",
            "|    time_elapsed       | 351        |\n",
            "|    total_timesteps    | 64000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -39.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 12799      |\n",
            "|    policy_loss        | 1.2e+08    |\n",
            "|    reward             | 1046065.06 |\n",
            "|    std                | 0.95       |\n",
            "|    value_loss         | 1.18e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 12900     |\n",
            "|    time_elapsed       | 353       |\n",
            "|    total_timesteps    | 64500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12899     |\n",
            "|    policy_loss        | 1.75e+08  |\n",
            "|    reward             | 1606901.6 |\n",
            "|    std                | 0.95      |\n",
            "|    value_loss         | 2.78e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 13000     |\n",
            "|    time_elapsed       | 356       |\n",
            "|    total_timesteps    | 65000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 12999     |\n",
            "|    policy_loss        | 2.57e+08  |\n",
            "|    reward             | 2220878.5 |\n",
            "|    std                | 0.95      |\n",
            "|    value_loss         | 5.42e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 13100     |\n",
            "|    time_elapsed       | 358       |\n",
            "|    total_timesteps    | 65500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13099     |\n",
            "|    policy_loss        | 3.03e+08  |\n",
            "|    reward             | 2833199.5 |\n",
            "|    std                | 0.949     |\n",
            "|    value_loss         | 8.4e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 13200     |\n",
            "|    time_elapsed       | 362       |\n",
            "|    total_timesteps    | 66000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13199     |\n",
            "|    policy_loss        | 4.51e+08  |\n",
            "|    reward             | 3830648.5 |\n",
            "|    std                | 0.949     |\n",
            "|    value_loss         | 1.6e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 13300     |\n",
            "|    time_elapsed       | 365       |\n",
            "|    total_timesteps    | 66500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13299     |\n",
            "|    policy_loss        | 6.15e+08  |\n",
            "|    reward             | 5528675.5 |\n",
            "|    std                | 0.949     |\n",
            "|    value_loss         | 3.25e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5689739.4315828085\n",
            "Sharpe:  1.0538965194502126\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 13400     |\n",
            "|    time_elapsed       | 369       |\n",
            "|    total_timesteps    | 67000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13399     |\n",
            "|    policy_loss        | 1.66e+08  |\n",
            "|    reward             | 1345421.5 |\n",
            "|    std                | 0.949     |\n",
            "|    value_loss         | 1.95e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 13500     |\n",
            "|    time_elapsed       | 371       |\n",
            "|    total_timesteps    | 67500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13499     |\n",
            "|    policy_loss        | 2.2e+08   |\n",
            "|    reward             | 1948878.6 |\n",
            "|    std                | 0.949     |\n",
            "|    value_loss         | 4.35e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 13600     |\n",
            "|    time_elapsed       | 374       |\n",
            "|    total_timesteps    | 68000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13599     |\n",
            "|    policy_loss        | 2.78e+08  |\n",
            "|    reward             | 2475914.2 |\n",
            "|    std                | 0.948     |\n",
            "|    value_loss         | 6.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 13700     |\n",
            "|    time_elapsed       | 376       |\n",
            "|    total_timesteps    | 68500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13699     |\n",
            "|    policy_loss        | 4.76e+08  |\n",
            "|    reward             | 3944121.8 |\n",
            "|    std                | 0.948     |\n",
            "|    value_loss         | 1.64e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 182       |\n",
            "|    iterations         | 13800     |\n",
            "|    time_elapsed       | 378       |\n",
            "|    total_timesteps    | 69000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13799     |\n",
            "|    policy_loss        | 5.4e+08   |\n",
            "|    reward             | 4631481.5 |\n",
            "|    std                | 0.948     |\n",
            "|    value_loss         | 2.3e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6067513.200453321\n",
            "Sharpe:  1.0769415332319352\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 13900     |\n",
            "|    time_elapsed       | 382       |\n",
            "|    total_timesteps    | 69500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13899     |\n",
            "|    policy_loss        | 1.3e+08   |\n",
            "|    reward             | 1178127.0 |\n",
            "|    std                | 0.947     |\n",
            "|    value_loss         | 1.45e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14000     |\n",
            "|    time_elapsed       | 385       |\n",
            "|    total_timesteps    | 70000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 13999     |\n",
            "|    policy_loss        | 1.91e+08  |\n",
            "|    reward             | 1738583.5 |\n",
            "|    std                | 0.947     |\n",
            "|    value_loss         | 3.16e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14100     |\n",
            "|    time_elapsed       | 388       |\n",
            "|    total_timesteps    | 70500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14099     |\n",
            "|    policy_loss        | 2.41e+08  |\n",
            "|    reward             | 2020684.1 |\n",
            "|    std                | 0.947     |\n",
            "|    value_loss         | 4.16e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14200     |\n",
            "|    time_elapsed       | 392       |\n",
            "|    total_timesteps    | 71000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14199     |\n",
            "|    policy_loss        | 4.01e+08  |\n",
            "|    reward             | 3159743.5 |\n",
            "|    std                | 0.946     |\n",
            "|    value_loss         | 1.22e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14300     |\n",
            "|    time_elapsed       | 394       |\n",
            "|    total_timesteps    | 71500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14299     |\n",
            "|    policy_loss        | 5.33e+08  |\n",
            "|    reward             | 4385111.5 |\n",
            "|    std                | 0.946     |\n",
            "|    value_loss         | 1.97e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5510617.291618813\n",
            "Sharpe:  1.0276169850324373\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14400     |\n",
            "|    time_elapsed       | 397       |\n",
            "|    total_timesteps    | 72000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14399     |\n",
            "|    policy_loss        | 1.15e+08  |\n",
            "|    reward             | 1067738.8 |\n",
            "|    std                | 0.946     |\n",
            "|    value_loss         | 1.11e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14500     |\n",
            "|    time_elapsed       | 399       |\n",
            "|    total_timesteps    | 72500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14499     |\n",
            "|    policy_loss        | 1.68e+08  |\n",
            "|    reward             | 1519589.9 |\n",
            "|    std                | 0.945     |\n",
            "|    value_loss         | 2.42e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14600     |\n",
            "|    time_elapsed       | 401       |\n",
            "|    total_timesteps    | 73000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14599     |\n",
            "|    policy_loss        | 2.34e+08  |\n",
            "|    reward             | 2100372.0 |\n",
            "|    std                | 0.945     |\n",
            "|    value_loss         | 4.72e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14700     |\n",
            "|    time_elapsed       | 404       |\n",
            "|    total_timesteps    | 73500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14699     |\n",
            "|    policy_loss        | 3.2e+08   |\n",
            "|    reward             | 2684672.8 |\n",
            "|    std                | 0.944     |\n",
            "|    value_loss         | 7.63e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 14800     |\n",
            "|    time_elapsed       | 408       |\n",
            "|    total_timesteps    | 74000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14799     |\n",
            "|    policy_loss        | 4.19e+08  |\n",
            "|    reward             | 3843573.8 |\n",
            "|    std                | 0.944     |\n",
            "|    value_loss         | 1.54e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 14900     |\n",
            "|    time_elapsed       | 411       |\n",
            "|    total_timesteps    | 74500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14899     |\n",
            "|    policy_loss        | 5.97e+08  |\n",
            "|    reward             | 5413042.0 |\n",
            "|    std                | 0.943     |\n",
            "|    value_loss         | 3.11e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5470409.78622022\n",
            "Sharpe:  1.0273472377018669\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15000     |\n",
            "|    time_elapsed       | 415       |\n",
            "|    total_timesteps    | 75000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 14999     |\n",
            "|    policy_loss        | 1.64e+08  |\n",
            "|    reward             | 1319266.9 |\n",
            "|    std                | 0.943     |\n",
            "|    value_loss         | 1.82e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15100     |\n",
            "|    time_elapsed       | 417       |\n",
            "|    total_timesteps    | 75500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15099     |\n",
            "|    policy_loss        | 2.2e+08   |\n",
            "|    reward             | 2007427.0 |\n",
            "|    std                | 0.943     |\n",
            "|    value_loss         | 3.94e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 181       |\n",
            "|    iterations         | 15200     |\n",
            "|    time_elapsed       | 419       |\n",
            "|    total_timesteps    | 76000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15199     |\n",
            "|    policy_loss        | 2.53e+08  |\n",
            "|    reward             | 2366415.0 |\n",
            "|    std                | 0.942     |\n",
            "|    value_loss         | 5.84e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15300     |\n",
            "|    time_elapsed       | 423       |\n",
            "|    total_timesteps    | 76500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15299     |\n",
            "|    policy_loss        | 4.16e+08  |\n",
            "|    reward             | 3564293.2 |\n",
            "|    std                | 0.942     |\n",
            "|    value_loss         | 1.34e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15400     |\n",
            "|    time_elapsed       | 425       |\n",
            "|    total_timesteps    | 77000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15399     |\n",
            "|    policy_loss        | 5.39e+08  |\n",
            "|    reward             | 4511066.0 |\n",
            "|    std                | 0.941     |\n",
            "|    value_loss         | 2.12e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5632025.118586427\n",
            "Sharpe:  1.045428615899804\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15500     |\n",
            "|    time_elapsed       | 429       |\n",
            "|    total_timesteps    | 77500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15499     |\n",
            "|    policy_loss        | 1.4e+08   |\n",
            "|    reward             | 1242079.6 |\n",
            "|    std                | 0.941     |\n",
            "|    value_loss         | 1.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15600     |\n",
            "|    time_elapsed       | 432       |\n",
            "|    total_timesteps    | 78000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15599     |\n",
            "|    policy_loss        | 2.19e+08  |\n",
            "|    reward             | 1787610.6 |\n",
            "|    std                | 0.941     |\n",
            "|    value_loss         | 3.49e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15700     |\n",
            "|    time_elapsed       | 436       |\n",
            "|    total_timesteps    | 78500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15699     |\n",
            "|    policy_loss        | 2.44e+08  |\n",
            "|    reward             | 2134494.5 |\n",
            "|    std                | 0.941     |\n",
            "|    value_loss         | 4.7e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15800     |\n",
            "|    time_elapsed       | 438       |\n",
            "|    total_timesteps    | 79000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15799     |\n",
            "|    policy_loss        | 4.05e+08  |\n",
            "|    reward             | 3319669.2 |\n",
            "|    std                | 0.94      |\n",
            "|    value_loss         | 1.21e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 15900     |\n",
            "|    time_elapsed       | 441       |\n",
            "|    total_timesteps    | 79500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15899     |\n",
            "|    policy_loss        | 5.29e+08  |\n",
            "|    reward             | 4100796.0 |\n",
            "|    std                | 0.94      |\n",
            "|    value_loss         | 2.29e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5984386.840521666\n",
            "Sharpe:  1.0851463496432974\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16000     |\n",
            "|    time_elapsed       | 443       |\n",
            "|    total_timesteps    | 80000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 15999     |\n",
            "|    policy_loss        | 1.26e+08  |\n",
            "|    reward             | 1069289.1 |\n",
            "|    std                | 0.939     |\n",
            "|    value_loss         | 1.19e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16100     |\n",
            "|    time_elapsed       | 445       |\n",
            "|    total_timesteps    | 80500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16099     |\n",
            "|    policy_loss        | 1.74e+08  |\n",
            "|    reward             | 1565206.8 |\n",
            "|    std                | 0.939     |\n",
            "|    value_loss         | 2.58e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16200     |\n",
            "|    time_elapsed       | 448       |\n",
            "|    total_timesteps    | 81000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16199     |\n",
            "|    policy_loss        | 2.27e+08  |\n",
            "|    reward             | 2127402.0 |\n",
            "|    std                | 0.939     |\n",
            "|    value_loss         | 4.51e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16300     |\n",
            "|    time_elapsed       | 451       |\n",
            "|    total_timesteps    | 81500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16299     |\n",
            "|    policy_loss        | 3e+08     |\n",
            "|    reward             | 2671653.2 |\n",
            "|    std                | 0.939     |\n",
            "|    value_loss         | 7.62e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16400     |\n",
            "|    time_elapsed       | 454       |\n",
            "|    total_timesteps    | 82000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16399     |\n",
            "|    policy_loss        | 4.55e+08  |\n",
            "|    reward             | 3823021.5 |\n",
            "|    std                | 0.939     |\n",
            "|    value_loss         | 1.53e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16500     |\n",
            "|    time_elapsed       | 458       |\n",
            "|    total_timesteps    | 82500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16499     |\n",
            "|    policy_loss        | 5.79e+08  |\n",
            "|    reward             | 5317349.0 |\n",
            "|    std                | 0.938     |\n",
            "|    value_loss         | 2.89e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5405421.380659602\n",
            "Sharpe:  1.0219249330573739\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 16600     |\n",
            "|    time_elapsed       | 461       |\n",
            "|    total_timesteps    | 83000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16599     |\n",
            "|    policy_loss        | 1.44e+08  |\n",
            "|    reward             | 1265065.6 |\n",
            "|    std                | 0.938     |\n",
            "|    value_loss         | 1.63e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16700     |\n",
            "|    time_elapsed       | 463       |\n",
            "|    total_timesteps    | 83500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16699     |\n",
            "|    policy_loss        | 2.46e+08  |\n",
            "|    reward             | 1950805.8 |\n",
            "|    std                | 0.938     |\n",
            "|    value_loss         | 3.98e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16800     |\n",
            "|    time_elapsed       | 465       |\n",
            "|    total_timesteps    | 84000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16799     |\n",
            "|    policy_loss        | 2.49e+08  |\n",
            "|    reward             | 2248424.5 |\n",
            "|    std                | 0.937     |\n",
            "|    value_loss         | 4.99e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 16900     |\n",
            "|    time_elapsed       | 468       |\n",
            "|    total_timesteps    | 84500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16899     |\n",
            "|    policy_loss        | 3.55e+08  |\n",
            "|    reward             | 3492462.8 |\n",
            "|    std                | 0.936     |\n",
            "|    value_loss         | 1.22e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 17000     |\n",
            "|    time_elapsed       | 470       |\n",
            "|    total_timesteps    | 85000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 16999     |\n",
            "|    policy_loss        | 5e+08     |\n",
            "|    reward             | 4178657.0 |\n",
            "|    std                | 0.936     |\n",
            "|    value_loss         | 1.72e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5296886.580836359\n",
            "Sharpe:  1.010292270259115\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 17100     |\n",
            "|    time_elapsed       | 474       |\n",
            "|    total_timesteps    | 85500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17099     |\n",
            "|    policy_loss        | 1.52e+08  |\n",
            "|    reward             | 1237631.5 |\n",
            "|    std                | 0.936     |\n",
            "|    value_loss         | 1.65e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 17200     |\n",
            "|    time_elapsed       | 477       |\n",
            "|    total_timesteps    | 86000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17199     |\n",
            "|    policy_loss        | 2.11e+08  |\n",
            "|    reward             | 1831260.2 |\n",
            "|    std                | 0.935     |\n",
            "|    value_loss         | 3.43e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 17300     |\n",
            "|    time_elapsed       | 480       |\n",
            "|    total_timesteps    | 86500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17299     |\n",
            "|    policy_loss        | 2.67e+08  |\n",
            "|    reward             | 2282315.5 |\n",
            "|    std                | 0.935     |\n",
            "|    value_loss         | 5.44e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 17400     |\n",
            "|    time_elapsed       | 483       |\n",
            "|    total_timesteps    | 87000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17399     |\n",
            "|    policy_loss        | 4.63e+08  |\n",
            "|    reward             | 3331653.5 |\n",
            "|    std                | 0.934     |\n",
            "|    value_loss         | 1.29e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 17500     |\n",
            "|    time_elapsed       | 485       |\n",
            "|    total_timesteps    | 87500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17499     |\n",
            "|    policy_loss        | 4.31e+08  |\n",
            "|    reward             | 3301079.2 |\n",
            "|    std                | 0.934     |\n",
            "|    value_loss         | 1.66e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5845770.833790583\n",
            "Sharpe:  1.064171424185702\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 180      |\n",
            "|    iterations         | 17600    |\n",
            "|    time_elapsed       | 488      |\n",
            "|    total_timesteps    | 88000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -39.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 17599    |\n",
            "|    policy_loss        | 1.15e+08 |\n",
            "|    reward             | 975629.5 |\n",
            "|    std                | 0.934    |\n",
            "|    value_loss         | 1.07e+13 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 17700     |\n",
            "|    time_elapsed       | 490       |\n",
            "|    total_timesteps    | 88500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17699     |\n",
            "|    policy_loss        | 1.92e+08  |\n",
            "|    reward             | 1604463.1 |\n",
            "|    std                | 0.933     |\n",
            "|    value_loss         | 2.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 17800     |\n",
            "|    time_elapsed       | 493       |\n",
            "|    total_timesteps    | 89000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17799     |\n",
            "|    policy_loss        | 2.43e+08  |\n",
            "|    reward             | 2198594.2 |\n",
            "|    std                | 0.933     |\n",
            "|    value_loss         | 5.08e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 17900     |\n",
            "|    time_elapsed       | 496       |\n",
            "|    total_timesteps    | 89500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17899     |\n",
            "|    policy_loss        | 3.51e+08  |\n",
            "|    reward             | 2879698.5 |\n",
            "|    std                | 0.932     |\n",
            "|    value_loss         | 8.62e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 18000     |\n",
            "|    time_elapsed       | 499       |\n",
            "|    total_timesteps    | 90000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 17999     |\n",
            "|    policy_loss        | 4.62e+08  |\n",
            "|    reward             | 4152185.5 |\n",
            "|    std                | 0.932     |\n",
            "|    value_loss         | 1.83e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 18100     |\n",
            "|    time_elapsed       | 503       |\n",
            "|    total_timesteps    | 90500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18099     |\n",
            "|    policy_loss        | 6.42e+08  |\n",
            "|    reward             | 5603260.0 |\n",
            "|    std                | 0.931     |\n",
            "|    value_loss         | 3.36e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5630687.156486774\n",
            "Sharpe:  1.0473878306334048\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 18200     |\n",
            "|    time_elapsed       | 506       |\n",
            "|    total_timesteps    | 91000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18199     |\n",
            "|    policy_loss        | 1.51e+08  |\n",
            "|    reward             | 1298471.9 |\n",
            "|    std                | 0.932     |\n",
            "|    value_loss         | 1.75e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 18300     |\n",
            "|    time_elapsed       | 508       |\n",
            "|    total_timesteps    | 91500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18299     |\n",
            "|    policy_loss        | 2.31e+08  |\n",
            "|    reward             | 2020272.2 |\n",
            "|    std                | 0.932     |\n",
            "|    value_loss         | 4.51e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 18400     |\n",
            "|    time_elapsed       | 511       |\n",
            "|    total_timesteps    | 92000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18399     |\n",
            "|    policy_loss        | 2.72e+08  |\n",
            "|    reward             | 2359574.2 |\n",
            "|    std                | 0.931     |\n",
            "|    value_loss         | 5.9e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 18500     |\n",
            "|    time_elapsed       | 513       |\n",
            "|    total_timesteps    | 92500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18499     |\n",
            "|    policy_loss        | 3.98e+08  |\n",
            "|    reward             | 3567266.5 |\n",
            "|    std                | 0.931     |\n",
            "|    value_loss         | 1.24e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 180       |\n",
            "|    iterations         | 18600     |\n",
            "|    time_elapsed       | 516       |\n",
            "|    total_timesteps    | 93000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18599     |\n",
            "|    policy_loss        | 5.61e+08  |\n",
            "|    reward             | 4839814.5 |\n",
            "|    std                | 0.93      |\n",
            "|    value_loss         | 2.45e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5817467.983495782\n",
            "Sharpe:  1.062881302520097\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 18700     |\n",
            "|    time_elapsed       | 520       |\n",
            "|    total_timesteps    | 93500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18699     |\n",
            "|    policy_loss        | 1.34e+08  |\n",
            "|    reward             | 1226342.5 |\n",
            "|    std                | 0.929     |\n",
            "|    value_loss         | 1.58e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 18800     |\n",
            "|    time_elapsed       | 523       |\n",
            "|    total_timesteps    | 94000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39       |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18799     |\n",
            "|    policy_loss        | 1.98e+08  |\n",
            "|    reward             | 1781731.6 |\n",
            "|    std                | 0.929     |\n",
            "|    value_loss         | 3.27e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 18900     |\n",
            "|    time_elapsed       | 526       |\n",
            "|    total_timesteps    | 94500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18899     |\n",
            "|    policy_loss        | 2.62e+08  |\n",
            "|    reward             | 2339915.0 |\n",
            "|    std                | 0.929     |\n",
            "|    value_loss         | 5.58e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19000     |\n",
            "|    time_elapsed       | 529       |\n",
            "|    total_timesteps    | 95000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 18999     |\n",
            "|    policy_loss        | 3.73e+08  |\n",
            "|    reward             | 3384320.8 |\n",
            "|    std                | 0.929     |\n",
            "|    value_loss         | 1.18e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19100     |\n",
            "|    time_elapsed       | 531       |\n",
            "|    total_timesteps    | 95500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19099     |\n",
            "|    policy_loss        | 4.25e+08  |\n",
            "|    reward             | 3854518.2 |\n",
            "|    std                | 0.928     |\n",
            "|    value_loss         | 1.5e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6099583.012222079\n",
            "Sharpe:  1.084694278587611\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19200     |\n",
            "|    time_elapsed       | 534       |\n",
            "|    total_timesteps    | 96000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19199     |\n",
            "|    policy_loss        | 1.11e+08  |\n",
            "|    reward             | 1017908.3 |\n",
            "|    std                | 0.927     |\n",
            "|    value_loss         | 1.03e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19300     |\n",
            "|    time_elapsed       | 536       |\n",
            "|    total_timesteps    | 96500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19299     |\n",
            "|    policy_loss        | 1.71e+08  |\n",
            "|    reward             | 1551751.0 |\n",
            "|    std                | 0.926     |\n",
            "|    value_loss         | 2.58e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19400     |\n",
            "|    time_elapsed       | 539       |\n",
            "|    total_timesteps    | 97000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19399     |\n",
            "|    policy_loss        | 2.42e+08  |\n",
            "|    reward             | 1929120.1 |\n",
            "|    std                | 0.926     |\n",
            "|    value_loss         | 4.99e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19500     |\n",
            "|    time_elapsed       | 543       |\n",
            "|    total_timesteps    | 97500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19499     |\n",
            "|    policy_loss        | 3.05e+08  |\n",
            "|    reward             | 2837196.0 |\n",
            "|    std                | 0.926     |\n",
            "|    value_loss         | 8.82e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19600     |\n",
            "|    time_elapsed       | 546       |\n",
            "|    total_timesteps    | 98000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19599     |\n",
            "|    policy_loss        | 4.28e+08  |\n",
            "|    reward             | 3818111.2 |\n",
            "|    std                | 0.925     |\n",
            "|    value_loss         | 1.59e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5906898.909090494\n",
            "Sharpe:  1.0737591800745314\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19700     |\n",
            "|    time_elapsed       | 550       |\n",
            "|    total_timesteps    | 98500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19699     |\n",
            "|    policy_loss        | 4.54e+08  |\n",
            "|    reward             | 1003712.4 |\n",
            "|    std                | 0.925     |\n",
            "|    value_loss         | 2.05e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19800     |\n",
            "|    time_elapsed       | 552       |\n",
            "|    total_timesteps    | 99000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19799     |\n",
            "|    policy_loss        | 1.51e+08  |\n",
            "|    reward             | 1324190.2 |\n",
            "|    std                | 0.924     |\n",
            "|    value_loss         | 1.79e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 19900     |\n",
            "|    time_elapsed       | 554       |\n",
            "|    total_timesteps    | 99500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19899     |\n",
            "|    policy_loss        | 2.39e+08  |\n",
            "|    reward             | 2045502.8 |\n",
            "|    std                | 0.923     |\n",
            "|    value_loss         | 4.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20000     |\n",
            "|    time_elapsed       | 556       |\n",
            "|    total_timesteps    | 100000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 19999     |\n",
            "|    policy_loss        | 2.85e+08  |\n",
            "|    reward             | 2451761.5 |\n",
            "|    std                | 0.923     |\n",
            "|    value_loss         | 6.38e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20100     |\n",
            "|    time_elapsed       | 559       |\n",
            "|    total_timesteps    | 100500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20099     |\n",
            "|    policy_loss        | 3.58e+08  |\n",
            "|    reward             | 3086293.0 |\n",
            "|    std                | 0.923     |\n",
            "|    value_loss         | 1.2e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20200     |\n",
            "|    time_elapsed       | 561       |\n",
            "|    total_timesteps    | 101000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20199     |\n",
            "|    policy_loss        | 5.73e+08  |\n",
            "|    reward             | 4863110.5 |\n",
            "|    std                | 0.923     |\n",
            "|    value_loss         | 2.53e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5637545.134867783\n",
            "Sharpe:  1.0441596989662392\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20300     |\n",
            "|    time_elapsed       | 565       |\n",
            "|    total_timesteps    | 101500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20299     |\n",
            "|    policy_loss        | 1.43e+08  |\n",
            "|    reward             | 1183283.6 |\n",
            "|    std                | 0.923     |\n",
            "|    value_loss         | 1.6e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20400     |\n",
            "|    time_elapsed       | 568       |\n",
            "|    total_timesteps    | 102000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20399     |\n",
            "|    policy_loss        | 2.12e+08  |\n",
            "|    reward             | 1787895.5 |\n",
            "|    std                | 0.923     |\n",
            "|    value_loss         | 3.33e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20500     |\n",
            "|    time_elapsed       | 572       |\n",
            "|    total_timesteps    | 102500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20499     |\n",
            "|    policy_loss        | 2.92e+08  |\n",
            "|    reward             | 2237812.2 |\n",
            "|    std                | 0.923     |\n",
            "|    value_loss         | 5.49e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20600     |\n",
            "|    time_elapsed       | 574       |\n",
            "|    total_timesteps    | 103000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20599     |\n",
            "|    policy_loss        | 3.61e+08  |\n",
            "|    reward             | 3198480.8 |\n",
            "|    std                | 0.922     |\n",
            "|    value_loss         | 1.12e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20700     |\n",
            "|    time_elapsed       | 577       |\n",
            "|    total_timesteps    | 103500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20699     |\n",
            "|    policy_loss        | 4.05e+08  |\n",
            "|    reward             | 3793569.2 |\n",
            "|    std                | 0.922     |\n",
            "|    value_loss         | 1.47e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5582462.2689307025\n",
            "Sharpe:  1.0417444788142125\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 179      |\n",
            "|    iterations         | 20800    |\n",
            "|    time_elapsed       | 579      |\n",
            "|    total_timesteps    | 104000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -38.8    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 20799    |\n",
            "|    policy_loss        | 1.1e+08  |\n",
            "|    reward             | 927426.8 |\n",
            "|    std                | 0.921    |\n",
            "|    value_loss         | 9.97e+12 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 20900     |\n",
            "|    time_elapsed       | 582       |\n",
            "|    total_timesteps    | 104500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20899     |\n",
            "|    policy_loss        | 1.81e+08  |\n",
            "|    reward             | 1640361.0 |\n",
            "|    std                | 0.921     |\n",
            "|    value_loss         | 2.7e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 21000     |\n",
            "|    time_elapsed       | 586       |\n",
            "|    total_timesteps    | 105000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 20999     |\n",
            "|    policy_loss        | 2.38e+08  |\n",
            "|    reward             | 2029595.9 |\n",
            "|    std                | 0.921     |\n",
            "|    value_loss         | 4.22e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 21100     |\n",
            "|    time_elapsed       | 590       |\n",
            "|    total_timesteps    | 105500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21099     |\n",
            "|    policy_loss        | 2.88e+08  |\n",
            "|    reward             | 2806045.5 |\n",
            "|    std                | 0.921     |\n",
            "|    value_loss         | 8.39e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 21200     |\n",
            "|    time_elapsed       | 593       |\n",
            "|    total_timesteps    | 106000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21199     |\n",
            "|    policy_loss        | 4.53e+08  |\n",
            "|    reward             | 3839394.0 |\n",
            "|    std                | 0.921     |\n",
            "|    value_loss         | 1.48e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5399714.450606277\n",
            "Sharpe:  1.0196022861444658\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 21300     |\n",
            "|    time_elapsed       | 596       |\n",
            "|    total_timesteps    | 106500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21299     |\n",
            "|    policy_loss        | 1.1e+08   |\n",
            "|    reward             | 1024766.4 |\n",
            "|    std                | 0.921     |\n",
            "|    value_loss         | 1.1e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 21400     |\n",
            "|    time_elapsed       | 598       |\n",
            "|    total_timesteps    | 107000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21399     |\n",
            "|    policy_loss        | 1.51e+08  |\n",
            "|    reward             | 1391250.1 |\n",
            "|    std                | 0.921     |\n",
            "|    value_loss         | 2e+13     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 21500     |\n",
            "|    time_elapsed       | 601       |\n",
            "|    total_timesteps    | 107500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21499     |\n",
            "|    policy_loss        | 2.45e+08  |\n",
            "|    reward             | 2109576.0 |\n",
            "|    std                | 0.92      |\n",
            "|    value_loss         | 4.59e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 21600     |\n",
            "|    time_elapsed       | 603       |\n",
            "|    total_timesteps    | 108000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21599     |\n",
            "|    policy_loss        | 2.98e+08  |\n",
            "|    reward             | 2508103.0 |\n",
            "|    std                | 0.92      |\n",
            "|    value_loss         | 6.71e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 179       |\n",
            "|    iterations         | 21700     |\n",
            "|    time_elapsed       | 606       |\n",
            "|    total_timesteps    | 108500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21699     |\n",
            "|    policy_loss        | 3.87e+08  |\n",
            "|    reward             | 3431827.5 |\n",
            "|    std                | 0.92      |\n",
            "|    value_loss         | 1.2e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 21800     |\n",
            "|    time_elapsed       | 609       |\n",
            "|    total_timesteps    | 109000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21799     |\n",
            "|    policy_loss        | 5.84e+08  |\n",
            "|    reward             | 5177768.5 |\n",
            "|    std                | 0.92      |\n",
            "|    value_loss         | 2.69e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5969245.834988089\n",
            "Sharpe:  1.0767099763696522\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 21900     |\n",
            "|    time_elapsed       | 613       |\n",
            "|    total_timesteps    | 109500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21899     |\n",
            "|    policy_loss        | 1.42e+08  |\n",
            "|    reward             | 1165214.2 |\n",
            "|    std                | 0.919     |\n",
            "|    value_loss         | 1.53e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22000     |\n",
            "|    time_elapsed       | 616       |\n",
            "|    total_timesteps    | 110000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 21999     |\n",
            "|    policy_loss        | 1.99e+08  |\n",
            "|    reward             | 1884930.0 |\n",
            "|    std                | 0.919     |\n",
            "|    value_loss         | 3.7e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22100     |\n",
            "|    time_elapsed       | 619       |\n",
            "|    total_timesteps    | 110500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22099     |\n",
            "|    policy_loss        | 2.5e+08   |\n",
            "|    reward             | 2320109.8 |\n",
            "|    std                | 0.919     |\n",
            "|    value_loss         | 5.46e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22200     |\n",
            "|    time_elapsed       | 621       |\n",
            "|    total_timesteps    | 111000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22199     |\n",
            "|    policy_loss        | 3.99e+08  |\n",
            "|    reward             | 3482072.2 |\n",
            "|    std                | 0.918     |\n",
            "|    value_loss         | 1.28e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22300     |\n",
            "|    time_elapsed       | 623       |\n",
            "|    total_timesteps    | 111500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22299     |\n",
            "|    policy_loss        | 4.42e+08  |\n",
            "|    reward             | 3986312.5 |\n",
            "|    std                | 0.919     |\n",
            "|    value_loss         | 1.62e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5800240.913297522\n",
            "Sharpe:  1.0600993430190953\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 22400      |\n",
            "|    time_elapsed       | 626        |\n",
            "|    total_timesteps    | 112000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -38.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 22399      |\n",
            "|    policy_loss        | 1.15e+08   |\n",
            "|    reward             | 1013854.44 |\n",
            "|    std                | 0.918      |\n",
            "|    value_loss         | 9.71e+12   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22500     |\n",
            "|    time_elapsed       | 629       |\n",
            "|    total_timesteps    | 112500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22499     |\n",
            "|    policy_loss        | 1.8e+08   |\n",
            "|    reward             | 1576224.8 |\n",
            "|    std                | 0.917     |\n",
            "|    value_loss         | 2.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22600     |\n",
            "|    time_elapsed       | 632       |\n",
            "|    total_timesteps    | 113000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22599     |\n",
            "|    policy_loss        | 2.37e+08  |\n",
            "|    reward             | 2076977.6 |\n",
            "|    std                | 0.917     |\n",
            "|    value_loss         | 4.25e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22700     |\n",
            "|    time_elapsed       | 635       |\n",
            "|    total_timesteps    | 113500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22699     |\n",
            "|    policy_loss        | 3.56e+08  |\n",
            "|    reward             | 2939075.0 |\n",
            "|    std                | 0.917     |\n",
            "|    value_loss         | 9.22e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22800     |\n",
            "|    time_elapsed       | 638       |\n",
            "|    total_timesteps    | 114000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22799     |\n",
            "|    policy_loss        | 4.73e+08  |\n",
            "|    reward             | 4065113.5 |\n",
            "|    std                | 0.917     |\n",
            "|    value_loss         | 1.78e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5745136.141718052\n",
            "Sharpe:  1.0514415687735872\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 22900     |\n",
            "|    time_elapsed       | 642       |\n",
            "|    total_timesteps    | 114500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22899     |\n",
            "|    policy_loss        | 1.17e+08  |\n",
            "|    reward             | 1028782.2 |\n",
            "|    std                | 0.917     |\n",
            "|    value_loss         | 1.15e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23000     |\n",
            "|    time_elapsed       | 644       |\n",
            "|    total_timesteps    | 115000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 22999     |\n",
            "|    policy_loss        | 1.69e+08  |\n",
            "|    reward             | 1412070.5 |\n",
            "|    std                | 0.916     |\n",
            "|    value_loss         | 2.11e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23100     |\n",
            "|    time_elapsed       | 646       |\n",
            "|    total_timesteps    | 115500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23099     |\n",
            "|    policy_loss        | 2.47e+08  |\n",
            "|    reward             | 2197509.0 |\n",
            "|    std                | 0.916     |\n",
            "|    value_loss         | 4.85e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23200     |\n",
            "|    time_elapsed       | 648       |\n",
            "|    total_timesteps    | 116000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23199     |\n",
            "|    policy_loss        | 3.11e+08  |\n",
            "|    reward             | 2645122.2 |\n",
            "|    std                | 0.916     |\n",
            "|    value_loss         | 7.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23300     |\n",
            "|    time_elapsed       | 651       |\n",
            "|    total_timesteps    | 116500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23299     |\n",
            "|    policy_loss        | 4.13e+08  |\n",
            "|    reward             | 3533547.2 |\n",
            "|    std                | 0.915     |\n",
            "|    value_loss         | 1.28e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23400     |\n",
            "|    time_elapsed       | 654       |\n",
            "|    total_timesteps    | 117000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23399     |\n",
            "|    policy_loss        | 5.51e+08  |\n",
            "|    reward             | 5025250.5 |\n",
            "|    std                | 0.915     |\n",
            "|    value_loss         | 2.76e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5725152.564092782\n",
            "Sharpe:  1.0509756566907416\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23500     |\n",
            "|    time_elapsed       | 658       |\n",
            "|    total_timesteps    | 117500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23499     |\n",
            "|    policy_loss        | 1.32e+08  |\n",
            "|    reward             | 1196433.2 |\n",
            "|    std                | 0.914     |\n",
            "|    value_loss         | 1.56e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23600     |\n",
            "|    time_elapsed       | 661       |\n",
            "|    total_timesteps    | 118000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23599     |\n",
            "|    policy_loss        | 2.17e+08  |\n",
            "|    reward             | 1920189.0 |\n",
            "|    std                | 0.913     |\n",
            "|    value_loss         | 3.84e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23700     |\n",
            "|    time_elapsed       | 664       |\n",
            "|    total_timesteps    | 118500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23699     |\n",
            "|    policy_loss        | 2.73e+08  |\n",
            "|    reward             | 2333956.8 |\n",
            "|    std                | 0.913     |\n",
            "|    value_loss         | 5.91e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23800     |\n",
            "|    time_elapsed       | 666       |\n",
            "|    total_timesteps    | 119000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23799     |\n",
            "|    policy_loss        | 3.91e+08  |\n",
            "|    reward             | 3540305.0 |\n",
            "|    std                | 0.912     |\n",
            "|    value_loss         | 1.27e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 23900     |\n",
            "|    time_elapsed       | 669       |\n",
            "|    total_timesteps    | 119500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 23899     |\n",
            "|    policy_loss        | 4.94e+08  |\n",
            "|    reward             | 4473638.5 |\n",
            "|    std                | 0.912     |\n",
            "|    value_loss         | 1.83e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5694831.640075634\n",
            "Sharpe:  1.0516072256417808\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 24000      |\n",
            "|    time_elapsed       | 671        |\n",
            "|    total_timesteps    | 120000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -38.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 23999      |\n",
            "|    policy_loss        | 1.1e+08    |\n",
            "|    reward             | 1037480.06 |\n",
            "|    std                | 0.912      |\n",
            "|    value_loss         | 1.17e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24100     |\n",
            "|    time_elapsed       | 674       |\n",
            "|    total_timesteps    | 120500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24099     |\n",
            "|    policy_loss        | 1.82e+08  |\n",
            "|    reward             | 1673844.6 |\n",
            "|    std                | 0.912     |\n",
            "|    value_loss         | 2.91e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24200     |\n",
            "|    time_elapsed       | 677       |\n",
            "|    total_timesteps    | 121000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24199     |\n",
            "|    policy_loss        | 2.36e+08  |\n",
            "|    reward             | 2164443.8 |\n",
            "|    std                | 0.912     |\n",
            "|    value_loss         | 4.71e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24300     |\n",
            "|    time_elapsed       | 681       |\n",
            "|    total_timesteps    | 121500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24299     |\n",
            "|    policy_loss        | 3.58e+08  |\n",
            "|    reward             | 3020609.0 |\n",
            "|    std                | 0.912     |\n",
            "|    value_loss         | 9.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24400     |\n",
            "|    time_elapsed       | 684       |\n",
            "|    total_timesteps    | 122000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24399     |\n",
            "|    policy_loss        | 4.04e+08  |\n",
            "|    reward             | 3865140.8 |\n",
            "|    std                | 0.912     |\n",
            "|    value_loss         | 1.52e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5359400.279889426\n",
            "Sharpe:  1.0199062786999662\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24500     |\n",
            "|    time_elapsed       | 687       |\n",
            "|    total_timesteps    | 122500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24499     |\n",
            "|    policy_loss        | 1.13e+08  |\n",
            "|    reward             | 1014558.5 |\n",
            "|    std                | 0.911     |\n",
            "|    value_loss         | 1.12e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24600     |\n",
            "|    time_elapsed       | 689       |\n",
            "|    total_timesteps    | 123000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24599     |\n",
            "|    policy_loss        | 1.54e+08  |\n",
            "|    reward             | 1442461.8 |\n",
            "|    std                | 0.91      |\n",
            "|    value_loss         | 2.12e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24700     |\n",
            "|    time_elapsed       | 691       |\n",
            "|    total_timesteps    | 123500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.4     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24699     |\n",
            "|    policy_loss        | 2.34e+08  |\n",
            "|    reward             | 2117831.2 |\n",
            "|    std                | 0.909     |\n",
            "|    value_loss         | 4.79e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24800     |\n",
            "|    time_elapsed       | 694       |\n",
            "|    total_timesteps    | 124000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24799     |\n",
            "|    policy_loss        | 3.02e+08  |\n",
            "|    reward             | 2629159.5 |\n",
            "|    std                | 0.909     |\n",
            "|    value_loss         | 7.23e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 24900     |\n",
            "|    time_elapsed       | 696       |\n",
            "|    total_timesteps    | 124500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24899     |\n",
            "|    policy_loss        | 4.16e+08  |\n",
            "|    reward             | 3616197.8 |\n",
            "|    std                | 0.908     |\n",
            "|    value_loss         | 1.34e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25000     |\n",
            "|    time_elapsed       | 700       |\n",
            "|    total_timesteps    | 125000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 24999     |\n",
            "|    policy_loss        | 5.35e+08  |\n",
            "|    reward             | 4967089.0 |\n",
            "|    std                | 0.908     |\n",
            "|    value_loss         | 2.61e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5509530.528132492\n",
            "Sharpe:  1.0309823023290798\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25100     |\n",
            "|    time_elapsed       | 703       |\n",
            "|    total_timesteps    | 125500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25099     |\n",
            "|    policy_loss        | 1.5e+08   |\n",
            "|    reward             | 1223878.4 |\n",
            "|    std                | 0.908     |\n",
            "|    value_loss         | 1.6e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25200     |\n",
            "|    time_elapsed       | 707       |\n",
            "|    total_timesteps    | 126000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25199     |\n",
            "|    policy_loss        | 2.27e+08  |\n",
            "|    reward             | 1921856.1 |\n",
            "|    std                | 0.908     |\n",
            "|    value_loss         | 3.92e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25300     |\n",
            "|    time_elapsed       | 709       |\n",
            "|    total_timesteps    | 126500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25299     |\n",
            "|    policy_loss        | 2.44e+08  |\n",
            "|    reward             | 2238731.5 |\n",
            "|    std                | 0.908     |\n",
            "|    value_loss         | 5.06e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25400     |\n",
            "|    time_elapsed       | 712       |\n",
            "|    total_timesteps    | 127000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25399     |\n",
            "|    policy_loss        | 3.66e+08  |\n",
            "|    reward             | 3140907.5 |\n",
            "|    std                | 0.907     |\n",
            "|    value_loss         | 1.06e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25500     |\n",
            "|    time_elapsed       | 714       |\n",
            "|    total_timesteps    | 127500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25499     |\n",
            "|    policy_loss        | 4.59e+08  |\n",
            "|    reward             | 3670964.0 |\n",
            "|    std                | 0.906     |\n",
            "|    value_loss         | 1.55e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5204814.533243896\n",
            "Sharpe:  1.0059759340510976\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 178        |\n",
            "|    iterations         | 25600      |\n",
            "|    time_elapsed       | 716        |\n",
            "|    total_timesteps    | 128000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -38.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 25599      |\n",
            "|    policy_loss        | 1.25e+08   |\n",
            "|    reward             | 1017306.75 |\n",
            "|    std                | 0.906      |\n",
            "|    value_loss         | 1.21e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25700     |\n",
            "|    time_elapsed       | 719       |\n",
            "|    total_timesteps    | 128500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25699     |\n",
            "|    policy_loss        | 1.92e+08  |\n",
            "|    reward             | 1697486.0 |\n",
            "|    std                | 0.906     |\n",
            "|    value_loss         | 2.99e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25800     |\n",
            "|    time_elapsed       | 723       |\n",
            "|    total_timesteps    | 129000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25799     |\n",
            "|    policy_loss        | 2.38e+08  |\n",
            "|    reward             | 2056277.5 |\n",
            "|    std                | 0.906     |\n",
            "|    value_loss         | 4.79e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 25900     |\n",
            "|    time_elapsed       | 726       |\n",
            "|    total_timesteps    | 129500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25899     |\n",
            "|    policy_loss        | 3.42e+08  |\n",
            "|    reward             | 2935843.0 |\n",
            "|    std                | 0.905     |\n",
            "|    value_loss         | 9e+13     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 26000     |\n",
            "|    time_elapsed       | 729       |\n",
            "|    total_timesteps    | 130000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 25999     |\n",
            "|    policy_loss        | 4.55e+08  |\n",
            "|    reward             | 3978748.2 |\n",
            "|    std                | 0.905     |\n",
            "|    value_loss         | 1.62e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5316950.298830512\n",
            "Sharpe:  1.0143811451709968\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 26100     |\n",
            "|    time_elapsed       | 732       |\n",
            "|    total_timesteps    | 130500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26099     |\n",
            "|    policy_loss        | 1.19e+08  |\n",
            "|    reward             | 1034469.7 |\n",
            "|    std                | 0.906     |\n",
            "|    value_loss         | 1.1e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 26200     |\n",
            "|    time_elapsed       | 735       |\n",
            "|    total_timesteps    | 131000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26199     |\n",
            "|    policy_loss        | 1.77e+08  |\n",
            "|    reward             | 1455685.0 |\n",
            "|    std                | 0.905     |\n",
            "|    value_loss         | 2.21e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 26300     |\n",
            "|    time_elapsed       | 737       |\n",
            "|    total_timesteps    | 131500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26299     |\n",
            "|    policy_loss        | 2.56e+08  |\n",
            "|    reward             | 2108589.5 |\n",
            "|    std                | 0.904     |\n",
            "|    value_loss         | 4.82e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 26400     |\n",
            "|    time_elapsed       | 739       |\n",
            "|    total_timesteps    | 132000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26399     |\n",
            "|    policy_loss        | 3.06e+08  |\n",
            "|    reward             | 2641773.8 |\n",
            "|    std                | 0.904     |\n",
            "|    value_loss         | 7.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 26500     |\n",
            "|    time_elapsed       | 742       |\n",
            "|    total_timesteps    | 132500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26499     |\n",
            "|    policy_loss        | 3.72e+08  |\n",
            "|    reward             | 3619855.8 |\n",
            "|    std                | 0.904     |\n",
            "|    value_loss         | 1.34e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 26600     |\n",
            "|    time_elapsed       | 745       |\n",
            "|    total_timesteps    | 133000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.2     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26599     |\n",
            "|    policy_loss        | 5.71e+08  |\n",
            "|    reward             | 5014772.5 |\n",
            "|    std                | 0.904     |\n",
            "|    value_loss         | 2.51e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5423523.193479185\n",
            "Sharpe:  1.027697213986543\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 26700     |\n",
            "|    time_elapsed       | 749       |\n",
            "|    total_timesteps    | 133500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26699     |\n",
            "|    policy_loss        | 1.35e+08  |\n",
            "|    reward             | 1252221.1 |\n",
            "|    std                | 0.903     |\n",
            "|    value_loss         | 1.61e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 26800     |\n",
            "|    time_elapsed       | 753       |\n",
            "|    total_timesteps    | 134000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26799     |\n",
            "|    policy_loss        | 2.27e+08  |\n",
            "|    reward             | 1944070.4 |\n",
            "|    std                | 0.903     |\n",
            "|    value_loss         | 4.27e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 26900     |\n",
            "|    time_elapsed       | 755       |\n",
            "|    total_timesteps    | 134500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26899     |\n",
            "|    policy_loss        | 2.93e+08  |\n",
            "|    reward             | 2484677.2 |\n",
            "|    std                | 0.902     |\n",
            "|    value_loss         | 6.62e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 27000     |\n",
            "|    time_elapsed       | 758       |\n",
            "|    total_timesteps    | 135000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 26999     |\n",
            "|    policy_loss        | 4.36e+08  |\n",
            "|    reward             | 3511158.8 |\n",
            "|    std                | 0.902     |\n",
            "|    value_loss         | 1.3e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 27100     |\n",
            "|    time_elapsed       | 760       |\n",
            "|    total_timesteps    | 135500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27099     |\n",
            "|    policy_loss        | 4.56e+08  |\n",
            "|    reward             | 4290271.0 |\n",
            "|    std                | 0.901     |\n",
            "|    value_loss         | 1.86e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5859458.620056333\n",
            "Sharpe:  1.0704207885163843\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 27200     |\n",
            "|    time_elapsed       | 763       |\n",
            "|    total_timesteps    | 136000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27199     |\n",
            "|    policy_loss        | 1.3e+08   |\n",
            "|    reward             | 1097252.5 |\n",
            "|    std                | 0.901     |\n",
            "|    value_loss         | 1.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 178       |\n",
            "|    iterations         | 27300     |\n",
            "|    time_elapsed       | 766       |\n",
            "|    total_timesteps    | 136500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27299     |\n",
            "|    policy_loss        | 2e+08     |\n",
            "|    reward             | 1762583.2 |\n",
            "|    std                | 0.901     |\n",
            "|    value_loss         | 3.31e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 27400     |\n",
            "|    time_elapsed       | 770       |\n",
            "|    total_timesteps    | 137000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27399     |\n",
            "|    policy_loss        | 2.42e+08  |\n",
            "|    reward             | 2239195.5 |\n",
            "|    std                | 0.901     |\n",
            "|    value_loss         | 5.51e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 27500     |\n",
            "|    time_elapsed       | 773       |\n",
            "|    total_timesteps    | 137500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27499     |\n",
            "|    policy_loss        | 3.84e+08  |\n",
            "|    reward             | 3262894.2 |\n",
            "|    std                | 0.901     |\n",
            "|    value_loss         | 1.09e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 27600     |\n",
            "|    time_elapsed       | 776       |\n",
            "|    total_timesteps    | 138000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27599     |\n",
            "|    policy_loss        | 5.21e+08  |\n",
            "|    reward             | 4425354.0 |\n",
            "|    std                | 0.901     |\n",
            "|    value_loss         | 2.06e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5852164.974391281\n",
            "Sharpe:  1.0635607371435336\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 27700     |\n",
            "|    time_elapsed       | 779       |\n",
            "|    total_timesteps    | 138500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27699     |\n",
            "|    policy_loss        | 1.08e+08  |\n",
            "|    reward             | 1060289.5 |\n",
            "|    std                | 0.9       |\n",
            "|    value_loss         | 1.15e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 27800     |\n",
            "|    time_elapsed       | 781       |\n",
            "|    total_timesteps    | 139000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27799     |\n",
            "|    policy_loss        | 1.62e+08  |\n",
            "|    reward             | 1485415.4 |\n",
            "|    std                | 0.9       |\n",
            "|    value_loss         | 2.39e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 27900     |\n",
            "|    time_elapsed       | 784       |\n",
            "|    total_timesteps    | 139500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38       |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27899     |\n",
            "|    policy_loss        | 2.31e+08  |\n",
            "|    reward             | 2176798.2 |\n",
            "|    std                | 0.899     |\n",
            "|    value_loss         | 4.91e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 28000     |\n",
            "|    time_elapsed       | 788       |\n",
            "|    total_timesteps    | 140000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 27999     |\n",
            "|    policy_loss        | 3.12e+08  |\n",
            "|    reward             | 2686475.2 |\n",
            "|    std                | 0.899     |\n",
            "|    value_loss         | 7.7e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 28100     |\n",
            "|    time_elapsed       | 792       |\n",
            "|    total_timesteps    | 140500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38       |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28099     |\n",
            "|    policy_loss        | 4.22e+08  |\n",
            "|    reward             | 3734404.0 |\n",
            "|    std                | 0.899     |\n",
            "|    value_loss         | 1.42e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 28200     |\n",
            "|    time_elapsed       | 796       |\n",
            "|    total_timesteps    | 141000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28199     |\n",
            "|    policy_loss        | 5.57e+08  |\n",
            "|    reward             | 5274749.0 |\n",
            "|    std                | 0.898     |\n",
            "|    value_loss         | 2.89e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5519286.085628504\n",
            "Sharpe:  1.0363983209058416\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 28300     |\n",
            "|    time_elapsed       | 799       |\n",
            "|    total_timesteps    | 141500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28299     |\n",
            "|    policy_loss        | 1.41e+08  |\n",
            "|    reward             | 1275773.5 |\n",
            "|    std                | 0.898     |\n",
            "|    value_loss         | 1.73e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 28400     |\n",
            "|    time_elapsed       | 802       |\n",
            "|    total_timesteps    | 142000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28399     |\n",
            "|    policy_loss        | 2.2e+08   |\n",
            "|    reward             | 1949363.0 |\n",
            "|    std                | 0.897     |\n",
            "|    value_loss         | 3.85e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 28500     |\n",
            "|    time_elapsed       | 804       |\n",
            "|    total_timesteps    | 142500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28499     |\n",
            "|    policy_loss        | 2.52e+08  |\n",
            "|    reward             | 2445244.0 |\n",
            "|    std                | 0.896     |\n",
            "|    value_loss         | 6.32e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 28600     |\n",
            "|    time_elapsed       | 807       |\n",
            "|    total_timesteps    | 143000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -38       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28599     |\n",
            "|    policy_loss        | 3.85e+08  |\n",
            "|    reward             | 3465194.0 |\n",
            "|    std                | 0.896     |\n",
            "|    value_loss         | 1.27e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 28700     |\n",
            "|    time_elapsed       | 809       |\n",
            "|    total_timesteps    | 143500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28699     |\n",
            "|    policy_loss        | 4.73e+08  |\n",
            "|    reward             | 4254740.0 |\n",
            "|    std                | 0.896     |\n",
            "|    value_loss         | 1.84e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5721380.647118482\n",
            "Sharpe:  1.0509887586303823\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 28800     |\n",
            "|    time_elapsed       | 814       |\n",
            "|    total_timesteps    | 144000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28799     |\n",
            "|    policy_loss        | 1.25e+08  |\n",
            "|    reward             | 1114724.2 |\n",
            "|    std                | 0.895     |\n",
            "|    value_loss         | 1.27e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 28900     |\n",
            "|    time_elapsed       | 817       |\n",
            "|    total_timesteps    | 144500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.9     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28899     |\n",
            "|    policy_loss        | 1.92e+08  |\n",
            "|    reward             | 1759443.4 |\n",
            "|    std                | 0.895     |\n",
            "|    value_loss         | 3.14e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29000     |\n",
            "|    time_elapsed       | 821       |\n",
            "|    total_timesteps    | 145000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 28999     |\n",
            "|    policy_loss        | 2.39e+08  |\n",
            "|    reward             | 2239874.5 |\n",
            "|    std                | 0.895     |\n",
            "|    value_loss         | 5.24e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29100     |\n",
            "|    time_elapsed       | 823       |\n",
            "|    total_timesteps    | 145500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29099     |\n",
            "|    policy_loss        | 3.75e+08  |\n",
            "|    reward             | 3240937.2 |\n",
            "|    std                | 0.895     |\n",
            "|    value_loss         | 1.08e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29200     |\n",
            "|    time_elapsed       | 826       |\n",
            "|    total_timesteps    | 146000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.9     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29199     |\n",
            "|    policy_loss        | 4.85e+08  |\n",
            "|    reward             | 4169390.5 |\n",
            "|    std                | 0.894     |\n",
            "|    value_loss         | 1.8e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5613681.217724368\n",
            "Sharpe:  1.0386437862543823\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29300     |\n",
            "|    time_elapsed       | 828       |\n",
            "|    total_timesteps    | 146500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29299     |\n",
            "|    policy_loss        | 1.22e+08  |\n",
            "|    reward             | 1092885.1 |\n",
            "|    std                | 0.894     |\n",
            "|    value_loss         | 1.26e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29400     |\n",
            "|    time_elapsed       | 831       |\n",
            "|    total_timesteps    | 147000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29399     |\n",
            "|    policy_loss        | 1.62e+08  |\n",
            "|    reward             | 1574011.6 |\n",
            "|    std                | 0.894     |\n",
            "|    value_loss         | 2.53e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29500     |\n",
            "|    time_elapsed       | 834       |\n",
            "|    total_timesteps    | 147500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29499     |\n",
            "|    policy_loss        | 2.38e+08  |\n",
            "|    reward             | 2210209.2 |\n",
            "|    std                | 0.893     |\n",
            "|    value_loss         | 5.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29600     |\n",
            "|    time_elapsed       | 838       |\n",
            "|    total_timesteps    | 148000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29599     |\n",
            "|    policy_loss        | 3.14e+08  |\n",
            "|    reward             | 2771601.5 |\n",
            "|    std                | 0.893     |\n",
            "|    value_loss         | 7.88e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29700     |\n",
            "|    time_elapsed       | 841       |\n",
            "|    total_timesteps    | 148500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29699     |\n",
            "|    policy_loss        | 4.57e+08  |\n",
            "|    reward             | 3845078.5 |\n",
            "|    std                | 0.892     |\n",
            "|    value_loss         | 1.56e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29800     |\n",
            "|    time_elapsed       | 844       |\n",
            "|    total_timesteps    | 149000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.8     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29799     |\n",
            "|    policy_loss        | 6e+08     |\n",
            "|    reward             | 5427397.5 |\n",
            "|    std                | 0.892     |\n",
            "|    value_loss         | 3.11e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5588012.089339565\n",
            "Sharpe:  1.0389035871210506\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 29900     |\n",
            "|    time_elapsed       | 847       |\n",
            "|    total_timesteps    | 149500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29899     |\n",
            "|    policy_loss        | 1.37e+08  |\n",
            "|    reward             | 1307046.2 |\n",
            "|    std                | 0.891     |\n",
            "|    value_loss         | 1.72e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30000     |\n",
            "|    time_elapsed       | 849       |\n",
            "|    total_timesteps    | 150000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 29999     |\n",
            "|    policy_loss        | 2.27e+08  |\n",
            "|    reward             | 1978426.0 |\n",
            "|    std                | 0.891     |\n",
            "|    value_loss         | 4.11e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30100     |\n",
            "|    time_elapsed       | 852       |\n",
            "|    total_timesteps    | 150500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30099     |\n",
            "|    policy_loss        | 2.77e+08  |\n",
            "|    reward             | 2390967.2 |\n",
            "|    std                | 0.891     |\n",
            "|    value_loss         | 6.06e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30200     |\n",
            "|    time_elapsed       | 855       |\n",
            "|    total_timesteps    | 151000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.8     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30199     |\n",
            "|    policy_loss        | 4.05e+08  |\n",
            "|    reward             | 3514908.8 |\n",
            "|    std                | 0.89      |\n",
            "|    value_loss         | 1.29e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30300     |\n",
            "|    time_elapsed       | 858       |\n",
            "|    total_timesteps    | 151500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30299     |\n",
            "|    policy_loss        | 4.34e+08  |\n",
            "|    reward             | 4209354.0 |\n",
            "|    std                | 0.889     |\n",
            "|    value_loss         | 1.81e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5474132.083351624\n",
            "Sharpe:  1.0290262417936487\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30400     |\n",
            "|    time_elapsed       | 862       |\n",
            "|    total_timesteps    | 152000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30399     |\n",
            "|    policy_loss        | 1.18e+08  |\n",
            "|    reward             | 1143317.6 |\n",
            "|    std                | 0.889     |\n",
            "|    value_loss         | 1.34e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30500     |\n",
            "|    time_elapsed       | 866       |\n",
            "|    total_timesteps    | 152500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30499     |\n",
            "|    policy_loss        | 1.89e+08  |\n",
            "|    reward             | 1790929.6 |\n",
            "|    std                | 0.889     |\n",
            "|    value_loss         | 3.42e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30600     |\n",
            "|    time_elapsed       | 868       |\n",
            "|    total_timesteps    | 153000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30599     |\n",
            "|    policy_loss        | 2.36e+08  |\n",
            "|    reward             | 2141137.2 |\n",
            "|    std                | 0.889     |\n",
            "|    value_loss         | 5.18e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30700     |\n",
            "|    time_elapsed       | 870       |\n",
            "|    total_timesteps    | 153500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30699     |\n",
            "|    policy_loss        | 3.96e+08  |\n",
            "|    reward             | 3447079.8 |\n",
            "|    std                | 0.889     |\n",
            "|    value_loss         | 1.21e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30800     |\n",
            "|    time_elapsed       | 873       |\n",
            "|    total_timesteps    | 154000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30799     |\n",
            "|    policy_loss        | 4.81e+08  |\n",
            "|    reward             | 4302032.5 |\n",
            "|    std                | 0.888     |\n",
            "|    value_loss         | 1.96e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600820.047940601\n",
            "Sharpe:  1.0416488608579175\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 30900     |\n",
            "|    time_elapsed       | 876       |\n",
            "|    total_timesteps    | 154500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30899     |\n",
            "|    policy_loss        | 1.21e+08  |\n",
            "|    reward             | 1053286.5 |\n",
            "|    std                | 0.888     |\n",
            "|    value_loss         | 1.21e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 31000     |\n",
            "|    time_elapsed       | 879       |\n",
            "|    total_timesteps    | 155000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 30999     |\n",
            "|    policy_loss        | 1.68e+08  |\n",
            "|    reward             | 1561039.0 |\n",
            "|    std                | 0.888     |\n",
            "|    value_loss         | 2.59e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 31100     |\n",
            "|    time_elapsed       | 882       |\n",
            "|    total_timesteps    | 155500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31099     |\n",
            "|    policy_loss        | 2.28e+08  |\n",
            "|    reward             | 2164572.8 |\n",
            "|    std                | 0.888     |\n",
            "|    value_loss         | 5.1e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 31200     |\n",
            "|    time_elapsed       | 886       |\n",
            "|    total_timesteps    | 156000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31199     |\n",
            "|    policy_loss        | 2.6e+08   |\n",
            "|    reward             | 2591613.5 |\n",
            "|    std                | 0.888     |\n",
            "|    value_loss         | 7.37e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 31300     |\n",
            "|    time_elapsed       | 889       |\n",
            "|    total_timesteps    | 156500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31299     |\n",
            "|    policy_loss        | 4.21e+08  |\n",
            "|    reward             | 3599268.5 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 1.44e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 31400     |\n",
            "|    time_elapsed       | 892       |\n",
            "|    total_timesteps    | 157000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31399     |\n",
            "|    policy_loss        | 5.78e+08  |\n",
            "|    reward             | 5180400.0 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 2.74e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5229651.13584103\n",
            "Sharpe:  1.0097638622463108\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 31500     |\n",
            "|    time_elapsed       | 894       |\n",
            "|    total_timesteps    | 157500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31499     |\n",
            "|    policy_loss        | 1.46e+08  |\n",
            "|    reward             | 1300217.8 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 1.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 31600     |\n",
            "|    time_elapsed       | 897       |\n",
            "|    total_timesteps    | 158000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31599     |\n",
            "|    policy_loss        | 2.21e+08  |\n",
            "|    reward             | 1887080.4 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 3.94e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 31700     |\n",
            "|    time_elapsed       | 900       |\n",
            "|    total_timesteps    | 158500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31699     |\n",
            "|    policy_loss        | 2.51e+08  |\n",
            "|    reward             | 2301067.8 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 5.64e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 31800     |\n",
            "|    time_elapsed       | 903       |\n",
            "|    total_timesteps    | 159000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31799     |\n",
            "|    policy_loss        | 3.92e+08  |\n",
            "|    reward             | 3559600.2 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 1.3e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 31900     |\n",
            "|    time_elapsed       | 907       |\n",
            "|    total_timesteps    | 159500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31899     |\n",
            "|    policy_loss        | 4.61e+08  |\n",
            "|    reward             | 4109614.5 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 1.8e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5154604.3026182\n",
            "Sharpe:  0.9993827099412932\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32000     |\n",
            "|    time_elapsed       | 911       |\n",
            "|    total_timesteps    | 160000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 31999     |\n",
            "|    policy_loss        | 1.21e+08  |\n",
            "|    reward             | 1190564.2 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 1.46e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32100     |\n",
            "|    time_elapsed       | 913       |\n",
            "|    total_timesteps    | 160500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32099     |\n",
            "|    policy_loss        | 1.94e+08  |\n",
            "|    reward             | 1696428.9 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 2.95e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32200     |\n",
            "|    time_elapsed       | 916       |\n",
            "|    total_timesteps    | 161000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32199     |\n",
            "|    policy_loss        | 2.35e+08  |\n",
            "|    reward             | 2030095.6 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 4.26e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32300     |\n",
            "|    time_elapsed       | 918       |\n",
            "|    total_timesteps    | 161500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32299     |\n",
            "|    policy_loss        | 3.53e+08  |\n",
            "|    reward             | 3305890.5 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 1.16e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32400     |\n",
            "|    time_elapsed       | 921       |\n",
            "|    total_timesteps    | 162000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32399     |\n",
            "|    policy_loss        | 4.52e+08  |\n",
            "|    reward             | 4033937.0 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 1.82e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5108724.05391377\n",
            "Sharpe:  0.9927987108802336\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 175        |\n",
            "|    iterations         | 32500      |\n",
            "|    time_elapsed       | 925        |\n",
            "|    total_timesteps    | 162500     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -37.7      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 32499      |\n",
            "|    policy_loss        | 1.13e+08   |\n",
            "|    reward             | 1033444.56 |\n",
            "|    std                | 0.887      |\n",
            "|    value_loss         | 1.12e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32600     |\n",
            "|    time_elapsed       | 928       |\n",
            "|    total_timesteps    | 163000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32599     |\n",
            "|    policy_loss        | 1.78e+08  |\n",
            "|    reward             | 1565081.8 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 2.61e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32700     |\n",
            "|    time_elapsed       | 932       |\n",
            "|    total_timesteps    | 163500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32699     |\n",
            "|    policy_loss        | 2.55e+08  |\n",
            "|    reward             | 2197224.0 |\n",
            "|    std                | 0.887     |\n",
            "|    value_loss         | 5.21e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32800     |\n",
            "|    time_elapsed       | 935       |\n",
            "|    total_timesteps    | 164000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32799     |\n",
            "|    policy_loss        | 3.11e+08  |\n",
            "|    reward             | 2784342.0 |\n",
            "|    std                | 0.886     |\n",
            "|    value_loss         | 8.16e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 32900     |\n",
            "|    time_elapsed       | 937       |\n",
            "|    total_timesteps    | 164500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32899     |\n",
            "|    policy_loss        | 3.95e+08  |\n",
            "|    reward             | 3711232.2 |\n",
            "|    std                | 0.886     |\n",
            "|    value_loss         | 1.44e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33000     |\n",
            "|    time_elapsed       | 940       |\n",
            "|    total_timesteps    | 165000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 32999     |\n",
            "|    policy_loss        | 6.26e+08  |\n",
            "|    reward             | 5518010.5 |\n",
            "|    std                | 0.885     |\n",
            "|    value_loss         | 3.18e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601695.668908296\n",
            "Sharpe:  1.0519416304167823\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33100     |\n",
            "|    time_elapsed       | 943       |\n",
            "|    total_timesteps    | 165500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33099     |\n",
            "|    policy_loss        | 1.61e+08  |\n",
            "|    reward             | 1277638.5 |\n",
            "|    std                | 0.885     |\n",
            "|    value_loss         | 1.8e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33200     |\n",
            "|    time_elapsed       | 946       |\n",
            "|    total_timesteps    | 166000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.6     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33199     |\n",
            "|    policy_loss        | 2.07e+08  |\n",
            "|    reward             | 1937974.4 |\n",
            "|    std                | 0.885     |\n",
            "|    value_loss         | 3.88e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33300     |\n",
            "|    time_elapsed       | 950       |\n",
            "|    total_timesteps    | 166500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33299     |\n",
            "|    policy_loss        | 2.62e+08  |\n",
            "|    reward             | 2328380.2 |\n",
            "|    std                | 0.884     |\n",
            "|    value_loss         | 5.9e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33400     |\n",
            "|    time_elapsed       | 953       |\n",
            "|    total_timesteps    | 167000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33399     |\n",
            "|    policy_loss        | 4.34e+08  |\n",
            "|    reward             | 3494604.0 |\n",
            "|    std                | 0.884     |\n",
            "|    value_loss         | 1.41e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33500     |\n",
            "|    time_elapsed       | 956       |\n",
            "|    total_timesteps    | 167500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33499     |\n",
            "|    policy_loss        | 4.35e+08  |\n",
            "|    reward             | 4142621.5 |\n",
            "|    std                | 0.883     |\n",
            "|    value_loss         | 1.77e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5341169.96342084\n",
            "Sharpe:  1.022530626195202\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33600     |\n",
            "|    time_elapsed       | 959       |\n",
            "|    total_timesteps    | 168000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33599     |\n",
            "|    policy_loss        | 1.33e+08  |\n",
            "|    reward             | 1202174.1 |\n",
            "|    std                | 0.883     |\n",
            "|    value_loss         | 1.53e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33700     |\n",
            "|    time_elapsed       | 962       |\n",
            "|    total_timesteps    | 168500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33699     |\n",
            "|    policy_loss        | 1.91e+08  |\n",
            "|    reward             | 1763827.8 |\n",
            "|    std                | 0.883     |\n",
            "|    value_loss         | 3.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33800     |\n",
            "|    time_elapsed       | 964       |\n",
            "|    total_timesteps    | 169000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33799     |\n",
            "|    policy_loss        | 2.26e+08  |\n",
            "|    reward             | 2104626.5 |\n",
            "|    std                | 0.883     |\n",
            "|    value_loss         | 4.49e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 33900     |\n",
            "|    time_elapsed       | 967       |\n",
            "|    total_timesteps    | 169500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33899     |\n",
            "|    policy_loss        | 3.3e+08   |\n",
            "|    reward             | 3176236.8 |\n",
            "|    std                | 0.883     |\n",
            "|    value_loss         | 1.02e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 34000     |\n",
            "|    time_elapsed       | 970       |\n",
            "|    total_timesteps    | 170000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 33999     |\n",
            "|    policy_loss        | 4.79e+08  |\n",
            "|    reward             | 4331520.0 |\n",
            "|    std                | 0.882     |\n",
            "|    value_loss         | 1.96e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5667899.2955609625\n",
            "Sharpe:  1.0566650845169527\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 34100     |\n",
            "|    time_elapsed       | 975       |\n",
            "|    total_timesteps    | 170500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34099     |\n",
            "|    policy_loss        | 1.1e+08   |\n",
            "|    reward             | 1065504.2 |\n",
            "|    std                | 0.881     |\n",
            "|    value_loss         | 1.22e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 34200     |\n",
            "|    time_elapsed       | 978       |\n",
            "|    total_timesteps    | 171000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34199     |\n",
            "|    policy_loss        | 1.82e+08  |\n",
            "|    reward             | 1619170.4 |\n",
            "|    std                | 0.881     |\n",
            "|    value_loss         | 2.65e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 34300     |\n",
            "|    time_elapsed       | 981       |\n",
            "|    total_timesteps    | 171500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34299     |\n",
            "|    policy_loss        | 2.4e+08   |\n",
            "|    reward             | 2235538.8 |\n",
            "|    std                | 0.881     |\n",
            "|    value_loss         | 5.49e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 34400     |\n",
            "|    time_elapsed       | 983       |\n",
            "|    total_timesteps    | 172000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34399     |\n",
            "|    policy_loss        | 3.14e+08  |\n",
            "|    reward             | 2803873.8 |\n",
            "|    std                | 0.881     |\n",
            "|    value_loss         | 8.3e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 34500     |\n",
            "|    time_elapsed       | 986       |\n",
            "|    total_timesteps    | 172500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34499     |\n",
            "|    policy_loss        | 3.95e+08  |\n",
            "|    reward             | 3728761.5 |\n",
            "|    std                | 0.881     |\n",
            "|    value_loss         | 1.45e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 175       |\n",
            "|    iterations         | 34600     |\n",
            "|    time_elapsed       | 988       |\n",
            "|    total_timesteps    | 173000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | -3.58e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34599     |\n",
            "|    policy_loss        | 6.09e+08  |\n",
            "|    reward             | 5260235.5 |\n",
            "|    std                | 0.881     |\n",
            "|    value_loss         | 3.15e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5514729.533659174\n",
            "Sharpe:  1.043247974402395\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 34700     |\n",
            "|    time_elapsed       | 992       |\n",
            "|    total_timesteps    | 173500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34699     |\n",
            "|    policy_loss        | 1.44e+08  |\n",
            "|    reward             | 1235852.1 |\n",
            "|    std                | 0.881     |\n",
            "|    value_loss         | 1.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 34800     |\n",
            "|    time_elapsed       | 996       |\n",
            "|    total_timesteps    | 174000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34799     |\n",
            "|    policy_loss        | 2.14e+08  |\n",
            "|    reward             | 2047800.9 |\n",
            "|    std                | 0.88      |\n",
            "|    value_loss         | 4.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 34900     |\n",
            "|    time_elapsed       | 999       |\n",
            "|    total_timesteps    | 174500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34899     |\n",
            "|    policy_loss        | 2.45e+08  |\n",
            "|    reward             | 2315510.8 |\n",
            "|    std                | 0.88      |\n",
            "|    value_loss         | 5.98e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35000     |\n",
            "|    time_elapsed       | 1002      |\n",
            "|    total_timesteps    | 175000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 34999     |\n",
            "|    policy_loss        | 3.77e+08  |\n",
            "|    reward             | 3424045.2 |\n",
            "|    std                | 0.879     |\n",
            "|    value_loss         | 1.29e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35100     |\n",
            "|    time_elapsed       | 1004      |\n",
            "|    total_timesteps    | 175500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35099     |\n",
            "|    policy_loss        | 5.03e+08  |\n",
            "|    reward             | 4216284.0 |\n",
            "|    std                | 0.879     |\n",
            "|    value_loss         | 2e+14     |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5541477.338661436\n",
            "Sharpe:  1.0466832976638585\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35200     |\n",
            "|    time_elapsed       | 1007      |\n",
            "|    total_timesteps    | 176000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35199     |\n",
            "|    policy_loss        | 1.28e+08  |\n",
            "|    reward             | 1228839.8 |\n",
            "|    std                | 0.879     |\n",
            "|    value_loss         | 1.62e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35300     |\n",
            "|    time_elapsed       | 1010      |\n",
            "|    total_timesteps    | 176500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35299     |\n",
            "|    policy_loss        | 1.95e+08  |\n",
            "|    reward             | 1787366.0 |\n",
            "|    std                | 0.879     |\n",
            "|    value_loss         | 3.39e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35400     |\n",
            "|    time_elapsed       | 1013      |\n",
            "|    total_timesteps    | 177000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35399     |\n",
            "|    policy_loss        | 2.38e+08  |\n",
            "|    reward             | 2224361.0 |\n",
            "|    std                | 0.879     |\n",
            "|    value_loss         | 5.04e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35500     |\n",
            "|    time_elapsed       | 1016      |\n",
            "|    total_timesteps    | 177500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35499     |\n",
            "|    policy_loss        | 3.49e+08  |\n",
            "|    reward             | 3343082.8 |\n",
            "|    std                | 0.879     |\n",
            "|    value_loss         | 1.15e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35600     |\n",
            "|    time_elapsed       | 1020      |\n",
            "|    total_timesteps    | 178000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35599     |\n",
            "|    policy_loss        | 4.18e+08  |\n",
            "|    reward             | 3921402.0 |\n",
            "|    std                | 0.878     |\n",
            "|    value_loss         | 1.66e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5726688.76083211\n",
            "Sharpe:  1.062695409040496\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 174        |\n",
            "|    iterations         | 35700      |\n",
            "|    time_elapsed       | 1023       |\n",
            "|    total_timesteps    | 178500     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -37.4      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 35699      |\n",
            "|    policy_loss        | 1.15e+08   |\n",
            "|    reward             | 1020048.94 |\n",
            "|    std                | 0.878      |\n",
            "|    value_loss         | 1.24e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35800     |\n",
            "|    time_elapsed       | 1026      |\n",
            "|    total_timesteps    | 179000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35799     |\n",
            "|    policy_loss        | 1.83e+08  |\n",
            "|    reward             | 1598160.5 |\n",
            "|    std                | 0.878     |\n",
            "|    value_loss         | 2.71e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 35900     |\n",
            "|    time_elapsed       | 1028      |\n",
            "|    total_timesteps    | 179500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35899     |\n",
            "|    policy_loss        | 2.49e+08  |\n",
            "|    reward             | 2194878.5 |\n",
            "|    std                | 0.877     |\n",
            "|    value_loss         | 5.32e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 36000     |\n",
            "|    time_elapsed       | 1031      |\n",
            "|    total_timesteps    | 180000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 35999     |\n",
            "|    policy_loss        | 3.11e+08  |\n",
            "|    reward             | 2770033.8 |\n",
            "|    std                | 0.877     |\n",
            "|    value_loss         | 7.96e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 36100     |\n",
            "|    time_elapsed       | 1033      |\n",
            "|    total_timesteps    | 180500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36099     |\n",
            "|    policy_loss        | 3.96e+08  |\n",
            "|    reward             | 3863213.2 |\n",
            "|    std                | 0.877     |\n",
            "|    value_loss         | 1.55e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 36200     |\n",
            "|    time_elapsed       | 1037      |\n",
            "|    total_timesteps    | 181000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36199     |\n",
            "|    policy_loss        | 6.19e+08  |\n",
            "|    reward             | 5572999.5 |\n",
            "|    std                | 0.877     |\n",
            "|    value_loss         | 3.25e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5594176.893150376\n",
            "Sharpe:  1.0494762602054755\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 36300     |\n",
            "|    time_elapsed       | 1041      |\n",
            "|    total_timesteps    | 181500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36299     |\n",
            "|    policy_loss        | 1.34e+08  |\n",
            "|    reward             | 1278645.0 |\n",
            "|    std                | 0.876     |\n",
            "|    value_loss         | 1.72e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 36400     |\n",
            "|    time_elapsed       | 1044      |\n",
            "|    total_timesteps    | 182000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36399     |\n",
            "|    policy_loss        | 2.11e+08  |\n",
            "|    reward             | 2019711.6 |\n",
            "|    std                | 0.876     |\n",
            "|    value_loss         | 4.27e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 36500     |\n",
            "|    time_elapsed       | 1047      |\n",
            "|    total_timesteps    | 182500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.3     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36499     |\n",
            "|    policy_loss        | 2.86e+08  |\n",
            "|    reward             | 2386418.2 |\n",
            "|    std                | 0.876     |\n",
            "|    value_loss         | 5.98e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 36600     |\n",
            "|    time_elapsed       | 1049      |\n",
            "|    total_timesteps    | 183000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36599     |\n",
            "|    policy_loss        | 4.12e+08  |\n",
            "|    reward             | 3439964.8 |\n",
            "|    std                | 0.875     |\n",
            "|    value_loss         | 1.32e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 174       |\n",
            "|    iterations         | 36700     |\n",
            "|    time_elapsed       | 1054      |\n",
            "|    total_timesteps    | 183500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36699     |\n",
            "|    policy_loss        | 4.92e+08  |\n",
            "|    reward             | 4710110.0 |\n",
            "|    std                | 0.875     |\n",
            "|    value_loss         | 2.07e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5758525.095577391\n",
            "Sharpe:  1.0667469989343188\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 36800     |\n",
            "|    time_elapsed       | 1057      |\n",
            "|    total_timesteps    | 184000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36799     |\n",
            "|    policy_loss        | 1.48e+08  |\n",
            "|    reward             | 1219527.5 |\n",
            "|    std                | 0.874     |\n",
            "|    value_loss         | 1.66e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 36900     |\n",
            "|    time_elapsed       | 1061      |\n",
            "|    total_timesteps    | 184500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36899     |\n",
            "|    policy_loss        | 2.2e+08   |\n",
            "|    reward             | 1762683.6 |\n",
            "|    std                | 0.874     |\n",
            "|    value_loss         | 3.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37000     |\n",
            "|    time_elapsed       | 1064      |\n",
            "|    total_timesteps    | 185000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 36999     |\n",
            "|    policy_loss        | 2.52e+08  |\n",
            "|    reward             | 2288995.5 |\n",
            "|    std                | 0.874     |\n",
            "|    value_loss         | 5.45e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37100     |\n",
            "|    time_elapsed       | 1068      |\n",
            "|    total_timesteps    | 185500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37099     |\n",
            "|    policy_loss        | 3.61e+08  |\n",
            "|    reward             | 3084666.0 |\n",
            "|    std                | 0.873     |\n",
            "|    value_loss         | 1.07e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37200     |\n",
            "|    time_elapsed       | 1071      |\n",
            "|    total_timesteps    | 186000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37199     |\n",
            "|    policy_loss        | 3.56e+08  |\n",
            "|    reward             | 3519478.0 |\n",
            "|    std                | 0.873     |\n",
            "|    value_loss         | 1.12e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5668245.77157993\n",
            "Sharpe:  1.0619798228133748\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 173      |\n",
            "|    iterations         | 37300    |\n",
            "|    time_elapsed       | 1073     |\n",
            "|    total_timesteps    | 186500   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -37.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 37299    |\n",
            "|    policy_loss        | 1.06e+08 |\n",
            "|    reward             | 945627.1 |\n",
            "|    std                | 0.873    |\n",
            "|    value_loss         | 1.01e+13 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37400     |\n",
            "|    time_elapsed       | 1076      |\n",
            "|    total_timesteps    | 187000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37399     |\n",
            "|    policy_loss        | 1.81e+08  |\n",
            "|    reward             | 1582230.9 |\n",
            "|    std                | 0.873     |\n",
            "|    value_loss         | 2.8e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37500     |\n",
            "|    time_elapsed       | 1078      |\n",
            "|    total_timesteps    | 187500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37499     |\n",
            "|    policy_loss        | 2.62e+08  |\n",
            "|    reward             | 2211375.0 |\n",
            "|    std                | 0.874     |\n",
            "|    value_loss         | 5.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37600     |\n",
            "|    time_elapsed       | 1082      |\n",
            "|    total_timesteps    | 188000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37599     |\n",
            "|    policy_loss        | 2.97e+08  |\n",
            "|    reward             | 2869416.8 |\n",
            "|    std                | 0.873     |\n",
            "|    value_loss         | 8.63e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37700     |\n",
            "|    time_elapsed       | 1085      |\n",
            "|    total_timesteps    | 188500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37699     |\n",
            "|    policy_loss        | 4.22e+08  |\n",
            "|    reward             | 3694165.2 |\n",
            "|    std                | 0.873     |\n",
            "|    value_loss         | 1.62e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37800     |\n",
            "|    time_elapsed       | 1089      |\n",
            "|    total_timesteps    | 189000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37799     |\n",
            "|    policy_loss        | 5.89e+08  |\n",
            "|    reward             | 5354654.0 |\n",
            "|    std                | 0.872     |\n",
            "|    value_loss         | 2.99e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5343124.336192179\n",
            "Sharpe:  1.025340264107782\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 37900     |\n",
            "|    time_elapsed       | 1092      |\n",
            "|    total_timesteps    | 189500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37899     |\n",
            "|    policy_loss        | 1.57e+08  |\n",
            "|    reward             | 1300056.5 |\n",
            "|    std                | 0.873     |\n",
            "|    value_loss         | 1.83e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38000     |\n",
            "|    time_elapsed       | 1095      |\n",
            "|    total_timesteps    | 190000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 37999     |\n",
            "|    policy_loss        | 2.18e+08  |\n",
            "|    reward             | 2095402.5 |\n",
            "|    std                | 0.872     |\n",
            "|    value_loss         | 4.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38100     |\n",
            "|    time_elapsed       | 1097      |\n",
            "|    total_timesteps    | 190500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38099     |\n",
            "|    policy_loss        | 2.6e+08   |\n",
            "|    reward             | 2514816.2 |\n",
            "|    std                | 0.872     |\n",
            "|    value_loss         | 6.37e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38200     |\n",
            "|    time_elapsed       | 1100      |\n",
            "|    total_timesteps    | 191000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38199     |\n",
            "|    policy_loss        | 3.78e+08  |\n",
            "|    reward             | 3381190.5 |\n",
            "|    std                | 0.871     |\n",
            "|    value_loss         | 1.32e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38300     |\n",
            "|    time_elapsed       | 1103      |\n",
            "|    total_timesteps    | 191500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38299     |\n",
            "|    policy_loss        | 5.26e+08  |\n",
            "|    reward             | 4739177.5 |\n",
            "|    std                | 0.871     |\n",
            "|    value_loss         | 2.26e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5462231.601927242\n",
            "Sharpe:  1.0411144633686595\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38400     |\n",
            "|    time_elapsed       | 1107      |\n",
            "|    total_timesteps    | 192000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38399     |\n",
            "|    policy_loss        | 1.48e+08  |\n",
            "|    reward             | 1285583.9 |\n",
            "|    std                | 0.871     |\n",
            "|    value_loss         | 1.74e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38500     |\n",
            "|    time_elapsed       | 1110      |\n",
            "|    total_timesteps    | 192500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38499     |\n",
            "|    policy_loss        | 1.9e+08   |\n",
            "|    reward             | 1876553.1 |\n",
            "|    std                | 0.87      |\n",
            "|    value_loss         | 3.69e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38600     |\n",
            "|    time_elapsed       | 1114      |\n",
            "|    total_timesteps    | 193000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38599     |\n",
            "|    policy_loss        | 2.89e+08  |\n",
            "|    reward             | 2346887.5 |\n",
            "|    std                | 0.87      |\n",
            "|    value_loss         | 5.9e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38700     |\n",
            "|    time_elapsed       | 1116      |\n",
            "|    total_timesteps    | 193500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38699     |\n",
            "|    policy_loss        | 3.62e+08  |\n",
            "|    reward             | 3195924.8 |\n",
            "|    std                | 0.87      |\n",
            "|    value_loss         | 1.08e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 38800     |\n",
            "|    time_elapsed       | 1119      |\n",
            "|    total_timesteps    | 194000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38799     |\n",
            "|    policy_loss        | 3.87e+08  |\n",
            "|    reward             | 3670748.8 |\n",
            "|    std                | 0.869     |\n",
            "|    value_loss         | 1.32e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5511418.406260754\n",
            "Sharpe:  1.050328304474653\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 173      |\n",
            "|    iterations         | 38900    |\n",
            "|    time_elapsed       | 1121     |\n",
            "|    total_timesteps    | 194500   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -37      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 38899    |\n",
            "|    policy_loss        | 1.12e+08 |\n",
            "|    reward             | 974818.2 |\n",
            "|    std                | 0.869    |\n",
            "|    value_loss         | 1.06e+13 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39000     |\n",
            "|    time_elapsed       | 1124      |\n",
            "|    total_timesteps    | 195000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 38999     |\n",
            "|    policy_loss        | 1.71e+08  |\n",
            "|    reward             | 1593182.4 |\n",
            "|    std                | 0.869     |\n",
            "|    value_loss         | 2.59e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39100     |\n",
            "|    time_elapsed       | 1127      |\n",
            "|    total_timesteps    | 195500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39099     |\n",
            "|    policy_loss        | 2.27e+08  |\n",
            "|    reward             | 2046794.4 |\n",
            "|    std                | 0.868     |\n",
            "|    value_loss         | 4.31e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39200     |\n",
            "|    time_elapsed       | 1131      |\n",
            "|    total_timesteps    | 196000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39199     |\n",
            "|    policy_loss        | 2.86e+08  |\n",
            "|    reward             | 2748484.0 |\n",
            "|    std                | 0.869     |\n",
            "|    value_loss         | 8.01e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39300     |\n",
            "|    time_elapsed       | 1134      |\n",
            "|    total_timesteps    | 196500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39299     |\n",
            "|    policy_loss        | 3.73e+08  |\n",
            "|    reward             | 3556497.5 |\n",
            "|    std                | 0.868     |\n",
            "|    value_loss         | 1.38e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5391541.821035175\n",
            "Sharpe:  1.0372316941872568\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 173        |\n",
            "|    iterations         | 39400      |\n",
            "|    time_elapsed       | 1137       |\n",
            "|    total_timesteps    | 197000     |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -37        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 39399      |\n",
            "|    policy_loss        | 1.09e+08   |\n",
            "|    reward             | 1016829.25 |\n",
            "|    std                | 0.867      |\n",
            "|    value_loss         | 1.09e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39500     |\n",
            "|    time_elapsed       | 1140      |\n",
            "|    total_timesteps    | 197500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37       |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39499     |\n",
            "|    policy_loss        | 1.42e+08  |\n",
            "|    reward             | 1341743.6 |\n",
            "|    std                | 0.867     |\n",
            "|    value_loss         | 1.9e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39600     |\n",
            "|    time_elapsed       | 1142      |\n",
            "|    total_timesteps    | 198000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39599     |\n",
            "|    policy_loss        | 2.12e+08  |\n",
            "|    reward             | 2066766.0 |\n",
            "|    std                | 0.867     |\n",
            "|    value_loss         | 4.58e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39700     |\n",
            "|    time_elapsed       | 1144      |\n",
            "|    total_timesteps    | 198500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39699     |\n",
            "|    policy_loss        | 2.91e+08  |\n",
            "|    reward             | 2461659.5 |\n",
            "|    std                | 0.867     |\n",
            "|    value_loss         | 6.4e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39800     |\n",
            "|    time_elapsed       | 1147      |\n",
            "|    total_timesteps    | 199000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -37       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39799     |\n",
            "|    policy_loss        | 3.39e+08  |\n",
            "|    reward             | 3231626.8 |\n",
            "|    std                | 0.867     |\n",
            "|    value_loss         | 1.04e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 39900     |\n",
            "|    time_elapsed       | 1150      |\n",
            "|    total_timesteps    | 199500    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36.9     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39899     |\n",
            "|    policy_loss        | 5.37e+08  |\n",
            "|    reward             | 4778898.0 |\n",
            "|    std                | 0.866     |\n",
            "|    value_loss         | 2.44e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5551277.496165517\n",
            "Sharpe:  1.0520616990724552\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 40000     |\n",
            "|    time_elapsed       | 1154      |\n",
            "|    total_timesteps    | 200000    |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 39999     |\n",
            "|    policy_loss        | 1.29e+08  |\n",
            "|    reward             | 1204629.4 |\n",
            "|    std                | 0.865     |\n",
            "|    value_loss         | 1.57e+13  |\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_a2c.save('/content/trained_models/trained_a2c.zip')"
      ],
      "metadata": {
        "id": "CcoCM6UV4Iug"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PPO\n",
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.005,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "trained_ppo = agent.train_model(model=model_ppo,\n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=200000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VfeIxLz4MR0",
        "outputId": "bf9b1fe7-f6e3-413c-b42e-3b01b0c2fa3a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
            "Using cpu device\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 259       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 7         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 3630724.2 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5217977.561607451\n",
            "Sharpe:  1.00179315489798\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 2         |\n",
            "|    time_elapsed         | 17        |\n",
            "|    total_timesteps      | 4096      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.77e+14  |\n",
            "|    n_updates            | 10        |\n",
            "|    policy_gradient_loss | -4.34e-07 |\n",
            "|    reward               | 2337778.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.4e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5460938.483455168\n",
            "Sharpe:  1.0306450255334192\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 201       |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 30        |\n",
            "|    total_timesteps      | 6144      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.06e+15  |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | -6.28e-07 |\n",
            "|    reward               | 1726227.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.01e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5382575.1351831015\n",
            "Sharpe:  1.0142333858263801\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 214       |\n",
            "|    iterations           | 4         |\n",
            "|    time_elapsed         | 38        |\n",
            "|    total_timesteps      | 8192      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.14e+15  |\n",
            "|    n_updates            | 30        |\n",
            "|    policy_gradient_loss | -5e-07    |\n",
            "|    reward               | 1052331.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.53e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 222       |\n",
            "|    iterations           | 5         |\n",
            "|    time_elapsed         | 46        |\n",
            "|    total_timesteps      | 10240     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.41e+15  |\n",
            "|    n_updates            | 40        |\n",
            "|    policy_gradient_loss | -6.93e-07 |\n",
            "|    reward               | 4299406.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.63e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5512896.768314865\n",
            "Sharpe:  1.035897493060076\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 221       |\n",
            "|    iterations           | 6         |\n",
            "|    time_elapsed         | 55        |\n",
            "|    total_timesteps      | 12288     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.77e+14  |\n",
            "|    n_updates            | 50        |\n",
            "|    policy_gradient_loss | -4.75e-07 |\n",
            "|    reward               | 2634015.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.77e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5240909.015814757\n",
            "Sharpe:  1.0047822790817051\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 228       |\n",
            "|    iterations           | 7         |\n",
            "|    time_elapsed         | 62        |\n",
            "|    total_timesteps      | 14336     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.69e+14  |\n",
            "|    n_updates            | 60        |\n",
            "|    policy_gradient_loss | -5.34e-07 |\n",
            "|    reward               | 1963836.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.81e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4689640.640510883\n",
            "Sharpe:  0.9444855069793007\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 224       |\n",
            "|    iterations           | 8         |\n",
            "|    time_elapsed         | 73        |\n",
            "|    total_timesteps      | 16384     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.1e+15   |\n",
            "|    n_updates            | 70        |\n",
            "|    policy_gradient_loss | -4.45e-07 |\n",
            "|    reward               | 1241435.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.24e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 229       |\n",
            "|    iterations           | 9         |\n",
            "|    time_elapsed         | 80        |\n",
            "|    total_timesteps      | 18432     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.09e+15  |\n",
            "|    n_updates            | 80        |\n",
            "|    policy_gradient_loss | -4.35e-07 |\n",
            "|    reward               | 4178277.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.23e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5308000.357653958\n",
            "Sharpe:  1.0118182972573486\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 234       |\n",
            "|    iterations           | 10        |\n",
            "|    time_elapsed         | 87        |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 9.5e+14   |\n",
            "|    n_updates            | 90        |\n",
            "|    policy_gradient_loss | -5.1e-07  |\n",
            "|    reward               | 3230827.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.98e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5497264.033689253\n",
            "Sharpe:  1.0289684904939094\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 230       |\n",
            "|    iterations           | 11        |\n",
            "|    time_elapsed         | 97        |\n",
            "|    total_timesteps      | 22528     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.99e+14  |\n",
            "|    n_updates            | 100       |\n",
            "|    policy_gradient_loss | -5.46e-07 |\n",
            "|    reward               | 2288895.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.59e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5208223.930479247\n",
            "Sharpe:  1.0015972042460373\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 234       |\n",
            "|    iterations           | 12        |\n",
            "|    time_elapsed         | 104       |\n",
            "|    total_timesteps      | 24576     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.27e+15  |\n",
            "|    n_updates            | 110       |\n",
            "|    policy_gradient_loss | -3.96e-07 |\n",
            "|    reward               | 1467567.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.36e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5285293.08795885\n",
            "Sharpe:  1.009608594788962\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 235       |\n",
            "|    iterations           | 13        |\n",
            "|    time_elapsed         | 113       |\n",
            "|    total_timesteps      | 26624     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.13e+15  |\n",
            "|    n_updates            | 120       |\n",
            "|    policy_gradient_loss | -4.73e-07 |\n",
            "|    reward               | 1005898.7 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.48e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 233       |\n",
            "|    iterations           | 14        |\n",
            "|    time_elapsed         | 122       |\n",
            "|    total_timesteps      | 28672     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.29e+15  |\n",
            "|    n_updates            | 130       |\n",
            "|    policy_gradient_loss | -3.53e-07 |\n",
            "|    reward               | 3534407.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.52e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5047816.660467647\n",
            "Sharpe:  0.9858419819100785\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 236       |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 129       |\n",
            "|    total_timesteps      | 30720     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.47e+14  |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | -5.93e-07 |\n",
            "|    reward               | 2327358.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.27e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5396758.064696637\n",
            "Sharpe:  1.0218024621185444\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 235       |\n",
            "|    iterations           | 16        |\n",
            "|    time_elapsed         | 139       |\n",
            "|    total_timesteps      | 32768     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.03e+15  |\n",
            "|    n_updates            | 150       |\n",
            "|    policy_gradient_loss | -5.25e-07 |\n",
            "|    reward               | 1818104.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.87e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5830675.449716357\n",
            "Sharpe:  1.0647423596032604\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 234       |\n",
            "|    iterations           | 17        |\n",
            "|    time_elapsed         | 148       |\n",
            "|    total_timesteps      | 34816     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.27e+15  |\n",
            "|    n_updates            | 160       |\n",
            "|    policy_gradient_loss | -6.08e-07 |\n",
            "|    reward               | 1020428.3 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.49e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 233       |\n",
            "|    iterations           | 18        |\n",
            "|    time_elapsed         | 158       |\n",
            "|    total_timesteps      | 36864     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.46e+15  |\n",
            "|    n_updates            | 170       |\n",
            "|    policy_gradient_loss | -3.44e-07 |\n",
            "|    reward               | 4000610.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.94e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5495782.724685918\n",
            "Sharpe:  1.0281137562371607\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 231       |\n",
            "|    iterations           | 19        |\n",
            "|    time_elapsed         | 168       |\n",
            "|    total_timesteps      | 38912     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.57e+14  |\n",
            "|    n_updates            | 180       |\n",
            "|    policy_gradient_loss | -4.65e-07 |\n",
            "|    reward               | 2738759.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.65e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5174631.799034836\n",
            "Sharpe:  0.9981001002580604\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 234       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 174       |\n",
            "|    total_timesteps      | 40960     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.27e+14  |\n",
            "|    n_updates            | 190       |\n",
            "|    policy_gradient_loss | -6.33e-07 |\n",
            "|    reward               | 2013165.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.76e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5350318.951374575\n",
            "Sharpe:  1.0122383558974613\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 232       |\n",
            "|    iterations           | 21        |\n",
            "|    time_elapsed         | 184       |\n",
            "|    total_timesteps      | 43008     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.16e+15  |\n",
            "|    n_updates            | 200       |\n",
            "|    policy_gradient_loss | -5.31e-07 |\n",
            "|    reward               | 1252494.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.27e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 233       |\n",
            "|    iterations           | 22        |\n",
            "|    time_elapsed         | 193       |\n",
            "|    total_timesteps      | 45056     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.23e+15  |\n",
            "|    n_updates            | 210       |\n",
            "|    policy_gradient_loss | -4.03e-07 |\n",
            "|    reward               | 4313749.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.51e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5377836.326165689\n",
            "Sharpe:  1.0232710563397827\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 235       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 200       |\n",
            "|    total_timesteps      | 47104     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.16e+15  |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -4.36e-07 |\n",
            "|    reward               | 3336999.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.2e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5651298.597665845\n",
            "Sharpe:  1.048695593175407\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 231       |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 212       |\n",
            "|    total_timesteps      | 49152     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.57e+14  |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | -4.68e-07 |\n",
            "|    reward               | 2254221.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.63e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5475231.158164045\n",
            "Sharpe:  1.027014707402212\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 233       |\n",
            "|    iterations           | 25        |\n",
            "|    time_elapsed         | 219       |\n",
            "|    total_timesteps      | 51200     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.06e+15  |\n",
            "|    n_updates            | 240       |\n",
            "|    policy_gradient_loss | -3.9e-07  |\n",
            "|    reward               | 1525177.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.35e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5313562.315136837\n",
            "Sharpe:  1.0117463359714851\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 232       |\n",
            "|    iterations           | 26        |\n",
            "|    time_elapsed         | 228       |\n",
            "|    total_timesteps      | 53248     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.26e+15  |\n",
            "|    n_updates            | 250       |\n",
            "|    policy_gradient_loss | -4.34e-07 |\n",
            "|    reward               | 1009054.3 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.62e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 232       |\n",
            "|    iterations           | 27        |\n",
            "|    time_elapsed         | 237       |\n",
            "|    total_timesteps      | 55296     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.1e+15   |\n",
            "|    n_updates            | 260       |\n",
            "|    policy_gradient_loss | -6.76e-07 |\n",
            "|    reward               | 3482343.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.63e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5240561.867154984\n",
            "Sharpe:  0.9998294967632978\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 234       |\n",
            "|    iterations           | 28        |\n",
            "|    time_elapsed         | 244       |\n",
            "|    total_timesteps      | 57344     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 2.38e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.6e+14   |\n",
            "|    n_updates            | 270       |\n",
            "|    policy_gradient_loss | -6.16e-07 |\n",
            "|    reward               | 2332456.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.32e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5297577.055140865\n",
            "Sharpe:  1.0103750781363525\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 233       |\n",
            "|    iterations           | 29        |\n",
            "|    time_elapsed         | 254       |\n",
            "|    total_timesteps      | 59392     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.01e+15  |\n",
            "|    n_updates            | 280       |\n",
            "|    policy_gradient_loss | -4.95e-07 |\n",
            "|    reward               | 1763520.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.01e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5104810.6537133325\n",
            "Sharpe:  0.990308296936717\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 234       |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 262       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.29e+15  |\n",
            "|    n_updates            | 290       |\n",
            "|    policy_gradient_loss | -3.62e-07 |\n",
            "|    reward               | 1038688.7 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.45e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 235       |\n",
            "|    iterations           | 31        |\n",
            "|    time_elapsed         | 269       |\n",
            "|    total_timesteps      | 63488     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.24e+15  |\n",
            "|    n_updates            | 300       |\n",
            "|    policy_gradient_loss | -5.1e-07  |\n",
            "|    reward               | 3850553.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.5e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4877510.990739036\n",
            "Sharpe:  0.965730720650656\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 233       |\n",
            "|    iterations           | 32        |\n",
            "|    time_elapsed         | 280       |\n",
            "|    total_timesteps      | 65536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.99e+14  |\n",
            "|    n_updates            | 310       |\n",
            "|    policy_gradient_loss | -6.58e-07 |\n",
            "|    reward               | 2732450.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.5e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5537638.604756095\n",
            "Sharpe:  1.03529997895011\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 235       |\n",
            "|    iterations           | 33        |\n",
            "|    time_elapsed         | 286       |\n",
            "|    total_timesteps      | 67584     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.74e+14  |\n",
            "|    n_updates            | 320       |\n",
            "|    policy_gradient_loss | -6.87e-07 |\n",
            "|    reward               | 2196865.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.6e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5239872.245927408\n",
            "Sharpe:  1.0024798800676666\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 235       |\n",
            "|    iterations           | 34        |\n",
            "|    time_elapsed         | 295       |\n",
            "|    total_timesteps      | 69632     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.09e+15  |\n",
            "|    n_updates            | 330       |\n",
            "|    policy_gradient_loss | -3.77e-07 |\n",
            "|    reward               | 1279962.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.43e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 235       |\n",
            "|    iterations           | 35        |\n",
            "|    time_elapsed         | 304       |\n",
            "|    total_timesteps      | 71680     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.3e+15   |\n",
            "|    n_updates            | 340       |\n",
            "|    policy_gradient_loss | -5.41e-07 |\n",
            "|    reward               | 4485207.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.59e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5694505.649551495\n",
            "Sharpe:  1.051747617376442\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 237       |\n",
            "|    iterations           | 36        |\n",
            "|    time_elapsed         | 310       |\n",
            "|    total_timesteps      | 73728     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.08e+15  |\n",
            "|    n_updates            | 350       |\n",
            "|    policy_gradient_loss | -5.09e-07 |\n",
            "|    reward               | 3229262.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.3e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5530204.404272248\n",
            "Sharpe:  1.0286734812710157\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 236       |\n",
            "|    iterations           | 37        |\n",
            "|    time_elapsed         | 320       |\n",
            "|    total_timesteps      | 75776     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.87e+14  |\n",
            "|    n_updates            | 360       |\n",
            "|    policy_gradient_loss | -5.2e-07  |\n",
            "|    reward               | 2200198.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.65e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5300782.80727805\n",
            "Sharpe:  1.0130471567940489\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 236       |\n",
            "|    iterations           | 38        |\n",
            "|    time_elapsed         | 328       |\n",
            "|    total_timesteps      | 77824     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.08e+15  |\n",
            "|    n_updates            | 370       |\n",
            "|    policy_gradient_loss | -5.36e-07 |\n",
            "|    reward               | 1489017.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.3e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5214511.665283236\n",
            "Sharpe:  1.002965024220474\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 238       |\n",
            "|    iterations           | 39        |\n",
            "|    time_elapsed         | 335       |\n",
            "|    total_timesteps      | 79872     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.21e+15  |\n",
            "|    n_updates            | 380       |\n",
            "|    policy_gradient_loss | -3.87e-07 |\n",
            "|    reward               | 1003412.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.5e+15   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 237       |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 344       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.25e+15  |\n",
            "|    n_updates            | 390       |\n",
            "|    policy_gradient_loss | -2.83e-07 |\n",
            "|    reward               | 3584196.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.51e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5298741.434924829\n",
            "Sharpe:  1.007368119797834\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 238       |\n",
            "|    iterations           | 41        |\n",
            "|    time_elapsed         | 352       |\n",
            "|    total_timesteps      | 83968     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.97e+14  |\n",
            "|    n_updates            | 400       |\n",
            "|    policy_gradient_loss | -5.89e-07 |\n",
            "|    reward               | 2362417.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.36e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5459201.951072341\n",
            "Sharpe:  1.0246902976061114\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 239       |\n",
            "|    iterations           | 42        |\n",
            "|    time_elapsed         | 359       |\n",
            "|    total_timesteps      | 86016     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 9.65e+14  |\n",
            "|    n_updates            | 410       |\n",
            "|    policy_gradient_loss | -4.73e-07 |\n",
            "|    reward               | 1752910.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.99e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5393447.64522808\n",
            "Sharpe:  1.0126124692683134\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 237       |\n",
            "|    iterations           | 43        |\n",
            "|    time_elapsed         | 370       |\n",
            "|    total_timesteps      | 88064     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.1e+15   |\n",
            "|    n_updates            | 420       |\n",
            "|    policy_gradient_loss | -5.59e-07 |\n",
            "|    reward               | 1071211.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.49e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 239       |\n",
            "|    iterations           | 44        |\n",
            "|    time_elapsed         | 376       |\n",
            "|    total_timesteps      | 90112     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.39e+15  |\n",
            "|    n_updates            | 430       |\n",
            "|    policy_gradient_loss | -5.1e-07  |\n",
            "|    reward               | 4191595.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.69e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5223437.085460765\n",
            "Sharpe:  1.0028999774890697\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 239       |\n",
            "|    iterations           | 45        |\n",
            "|    time_elapsed         | 384       |\n",
            "|    total_timesteps      | 92160     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.18e+14  |\n",
            "|    n_updates            | 440       |\n",
            "|    policy_gradient_loss | -6.28e-07 |\n",
            "|    reward               | 2824315.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.65e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5437760.459190466\n",
            "Sharpe:  1.0259329280551888\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 238       |\n",
            "|    iterations           | 46        |\n",
            "|    time_elapsed         | 394       |\n",
            "|    total_timesteps      | 94208     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.77e+14  |\n",
            "|    n_updates            | 450       |\n",
            "|    policy_gradient_loss | -6.14e-07 |\n",
            "|    reward               | 2078461.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.75e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5667456.415541606\n",
            "Sharpe:  1.055633707388568\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 47        |\n",
            "|    time_elapsed         | 400       |\n",
            "|    total_timesteps      | 96256     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.11e+15  |\n",
            "|    n_updates            | 460       |\n",
            "|    policy_gradient_loss | -4.6e-07  |\n",
            "|    reward               | 1288846.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.41e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 48        |\n",
            "|    time_elapsed         | 409       |\n",
            "|    total_timesteps      | 98304     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.41e+15  |\n",
            "|    n_updates            | 470       |\n",
            "|    policy_gradient_loss | -4.48e-07 |\n",
            "|    reward               | 3800588.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.7e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5200040.439221876\n",
            "Sharpe:  1.0003291514222448\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 238       |\n",
            "|    iterations           | 49        |\n",
            "|    time_elapsed         | 420       |\n",
            "|    total_timesteps      | 100352    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.03e+15  |\n",
            "|    n_updates            | 480       |\n",
            "|    policy_gradient_loss | -5.68e-07 |\n",
            "|    reward               | 3183841.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.05e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5274675.029897279\n",
            "Sharpe:  1.0054078185245507\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 239       |\n",
            "|    iterations           | 50        |\n",
            "|    time_elapsed         | 427       |\n",
            "|    total_timesteps      | 102400    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.45e+14  |\n",
            "|    n_updates            | 490       |\n",
            "|    policy_gradient_loss | -5.78e-07 |\n",
            "|    reward               | 2171774.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.49e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5465899.527258534\n",
            "Sharpe:  1.0283818923765429\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 238       |\n",
            "|    iterations           | 51        |\n",
            "|    time_elapsed         | 438       |\n",
            "|    total_timesteps      | 104448    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.33e+15  |\n",
            "|    n_updates            | 500       |\n",
            "|    policy_gradient_loss | -6.03e-07 |\n",
            "|    reward               | 1492395.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.17e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5261766.764203401\n",
            "Sharpe:  1.0067870118166802\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 239        |\n",
            "|    iterations           | 52         |\n",
            "|    time_elapsed         | 444        |\n",
            "|    total_timesteps      | 106496     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0        |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.1      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 1.24e+15   |\n",
            "|    n_updates            | 510        |\n",
            "|    policy_gradient_loss | -4.31e-07  |\n",
            "|    reward               | 1024441.06 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 2.6e+15    |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 239       |\n",
            "|    iterations           | 53        |\n",
            "|    time_elapsed         | 452       |\n",
            "|    total_timesteps      | 108544    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.18e+15  |\n",
            "|    n_updates            | 520       |\n",
            "|    policy_gradient_loss | -5.83e-07 |\n",
            "|    reward               | 3516629.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.4e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5005356.343905756\n",
            "Sharpe:  0.9782968822555234\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 239       |\n",
            "|    iterations           | 54        |\n",
            "|    time_elapsed         | 462       |\n",
            "|    total_timesteps      | 110592    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.52e+14  |\n",
            "|    n_updates            | 530       |\n",
            "|    policy_gradient_loss | -5.98e-07 |\n",
            "|    reward               | 2341355.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.31e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5347210.186828433\n",
            "Sharpe:  1.0161905084416902\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 55        |\n",
            "|    time_elapsed         | 468       |\n",
            "|    total_timesteps      | 112640    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.93e+14  |\n",
            "|    n_updates            | 540       |\n",
            "|    policy_gradient_loss | -3.43e-07 |\n",
            "|    reward               | 1778203.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.84e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5270986.851830914\n",
            "Sharpe:  1.004341688811263\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 56        |\n",
            "|    time_elapsed         | 477       |\n",
            "|    total_timesteps      | 114688    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.37e+15  |\n",
            "|    n_updates            | 550       |\n",
            "|    policy_gradient_loss | -3.16e-07 |\n",
            "|    reward               | 1026441.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.4e+15   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 57        |\n",
            "|    time_elapsed         | 486       |\n",
            "|    total_timesteps      | 116736    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.17e+15  |\n",
            "|    n_updates            | 560       |\n",
            "|    policy_gradient_loss | -4.7e-07  |\n",
            "|    reward               | 4007895.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.49e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5167636.419508447\n",
            "Sharpe:  0.9994646350269778\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 241       |\n",
            "|    iterations           | 58        |\n",
            "|    time_elapsed         | 492       |\n",
            "|    total_timesteps      | 118784    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.79e+14  |\n",
            "|    n_updates            | 570       |\n",
            "|    policy_gradient_loss | -4.62e-07 |\n",
            "|    reward               | 2826348.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.7e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5433115.477242596\n",
            "Sharpe:  1.0256869986279256\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 59        |\n",
            "|    time_elapsed         | 502       |\n",
            "|    total_timesteps      | 120832    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.74e+14  |\n",
            "|    n_updates            | 580       |\n",
            "|    policy_gradient_loss | -5.61e-07 |\n",
            "|    reward               | 2066842.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.66e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5281249.900225387\n",
            "Sharpe:  1.0110109632984299\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 60        |\n",
            "|    time_elapsed         | 510       |\n",
            "|    total_timesteps      | 122880    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.28e+15  |\n",
            "|    n_updates            | 590       |\n",
            "|    policy_gradient_loss | -4.71e-07 |\n",
            "|    reward               | 1329703.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.35e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 241       |\n",
            "|    iterations           | 61        |\n",
            "|    time_elapsed         | 517       |\n",
            "|    total_timesteps      | 124928    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.23e+15  |\n",
            "|    n_updates            | 600       |\n",
            "|    policy_gradient_loss | -3.64e-07 |\n",
            "|    reward               | 3897580.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.51e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5042862.207627599\n",
            "Sharpe:  0.9865525934652852\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 62        |\n",
            "|    time_elapsed         | 527       |\n",
            "|    total_timesteps      | 126976    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 9.78e+14  |\n",
            "|    n_updates            | 610       |\n",
            "|    policy_gradient_loss | -4.91e-07 |\n",
            "|    reward               | 3295736.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.06e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5349908.999981619\n",
            "Sharpe:  1.0104012126460697\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 241       |\n",
            "|    iterations           | 63        |\n",
            "|    time_elapsed         | 534       |\n",
            "|    total_timesteps      | 129024    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.06e+14  |\n",
            "|    n_updates            | 620       |\n",
            "|    policy_gradient_loss | -7.14e-07 |\n",
            "|    reward               | 2090435.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.59e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5120413.241139941\n",
            "Sharpe:  0.9935999031576829\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 241       |\n",
            "|    iterations           | 64        |\n",
            "|    time_elapsed         | 542       |\n",
            "|    total_timesteps      | 131072    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 9.98e+14  |\n",
            "|    n_updates            | 630       |\n",
            "|    policy_gradient_loss | -5.05e-07 |\n",
            "|    reward               | 1553281.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.17e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5241719.519785868\n",
            "Sharpe:  1.0086100619417655\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 240       |\n",
            "|    iterations           | 65        |\n",
            "|    time_elapsed         | 552       |\n",
            "|    total_timesteps      | 133120    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.07e+15  |\n",
            "|    n_updates            | 640       |\n",
            "|    policy_gradient_loss | -5.05e-07 |\n",
            "|    reward               | 1017555.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.25e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 241       |\n",
            "|    iterations           | 66        |\n",
            "|    time_elapsed         | 558       |\n",
            "|    total_timesteps      | 135168    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.24e+15  |\n",
            "|    n_updates            | 650       |\n",
            "|    policy_gradient_loss | -4.41e-07 |\n",
            "|    reward               | 3458368.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.53e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5485254.215771513\n",
            "Sharpe:  1.0290650767220333\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 241       |\n",
            "|    iterations           | 67        |\n",
            "|    time_elapsed         | 567       |\n",
            "|    total_timesteps      | 137216    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.58e+14  |\n",
            "|    n_updates            | 660       |\n",
            "|    policy_gradient_loss | -7e-07    |\n",
            "|    reward               | 2274296.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.31e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5261669.91384993\n",
            "Sharpe:  1.0061522485712036\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 241       |\n",
            "|    iterations           | 68        |\n",
            "|    time_elapsed         | 576       |\n",
            "|    total_timesteps      | 139264    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 9.53e+14  |\n",
            "|    n_updates            | 670       |\n",
            "|    policy_gradient_loss | -6.39e-07 |\n",
            "|    reward               | 1749376.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.99e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5280181.364547242\n",
            "Sharpe:  1.0056792165228716\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 69        |\n",
            "|    time_elapsed         | 582       |\n",
            "|    total_timesteps      | 141312    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.14e+15  |\n",
            "|    n_updates            | 680       |\n",
            "|    policy_gradient_loss | -5.73e-07 |\n",
            "|    reward               | 976530.4  |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.35e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 70        |\n",
            "|    time_elapsed         | 592       |\n",
            "|    total_timesteps      | 143360    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.2e+15   |\n",
            "|    n_updates            | 690       |\n",
            "|    policy_gradient_loss | -4.35e-07 |\n",
            "|    reward               | 4118317.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.48e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5329203.170385965\n",
            "Sharpe:  1.0149533498362129\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 71        |\n",
            "|    time_elapsed         | 600       |\n",
            "|    total_timesteps      | 145408    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.24e+14  |\n",
            "|    n_updates            | 700       |\n",
            "|    policy_gradient_loss | -5.88e-07 |\n",
            "|    reward               | 2775614.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.63e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5319573.269146046\n",
            "Sharpe:  1.0091576139780982\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 72        |\n",
            "|    time_elapsed         | 607       |\n",
            "|    total_timesteps      | 147456    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.21e+14  |\n",
            "|    n_updates            | 710       |\n",
            "|    policy_gradient_loss | -4.73e-07 |\n",
            "|    reward               | 2036311.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.69e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5460609.226120847\n",
            "Sharpe:  1.0292480929258043\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 73        |\n",
            "|    time_elapsed         | 617       |\n",
            "|    total_timesteps      | 149504    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.12e+15  |\n",
            "|    n_updates            | 720       |\n",
            "|    policy_gradient_loss | -4.83e-07 |\n",
            "|    reward               | 1321141.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.33e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 74        |\n",
            "|    time_elapsed         | 624       |\n",
            "|    total_timesteps      | 151552    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.15e+15  |\n",
            "|    n_updates            | 730       |\n",
            "|    policy_gradient_loss | -6.07e-07 |\n",
            "|    reward               | 4325828.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.38e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5289971.362157102\n",
            "Sharpe:  1.007037716180493\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 75        |\n",
            "|    time_elapsed         | 632       |\n",
            "|    total_timesteps      | 153600    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.05e+15  |\n",
            "|    n_updates            | 740       |\n",
            "|    policy_gradient_loss | -4.31e-07 |\n",
            "|    reward               | 3421000.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.11e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5541353.712057312\n",
            "Sharpe:  1.0355824722261389\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 76        |\n",
            "|    time_elapsed         | 642       |\n",
            "|    total_timesteps      | 155648    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.79e+14  |\n",
            "|    n_updates            | 750       |\n",
            "|    policy_gradient_loss | -5.54e-07 |\n",
            "|    reward               | 2144387.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.63e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4991425.259973618\n",
            "Sharpe:  0.9740816908622251\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 77        |\n",
            "|    time_elapsed         | 649       |\n",
            "|    total_timesteps      | 157696    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.17e+15  |\n",
            "|    n_updates            | 760       |\n",
            "|    policy_gradient_loss | -4.99e-07 |\n",
            "|    reward               | 1559614.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.32e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5712776.579866244\n",
            "Sharpe:  1.0525409718065124\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 242        |\n",
            "|    iterations           | 78         |\n",
            "|    time_elapsed         | 657        |\n",
            "|    total_timesteps      | 159744     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0        |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.1      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 1.01e+15   |\n",
            "|    n_updates            | 770        |\n",
            "|    policy_gradient_loss | -5.22e-07  |\n",
            "|    reward               | 1036462.25 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 2.21e+15   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 79        |\n",
            "|    time_elapsed         | 666       |\n",
            "|    total_timesteps      | 161792    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.45e+15  |\n",
            "|    n_updates            | 780       |\n",
            "|    policy_gradient_loss | -4.54e-07 |\n",
            "|    reward               | 3610717.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.94e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5533488.449789725\n",
            "Sharpe:  1.0329511426758813\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 80        |\n",
            "|    time_elapsed         | 673       |\n",
            "|    total_timesteps      | 163840    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.53e+14  |\n",
            "|    n_updates            | 790       |\n",
            "|    policy_gradient_loss | -7.56e-07 |\n",
            "|    reward               | 2185228.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.32e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5179813.697499424\n",
            "Sharpe:  1.0016403476244649\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 81        |\n",
            "|    time_elapsed         | 683       |\n",
            "|    total_timesteps      | 165888    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.97e+14  |\n",
            "|    n_updates            | 800       |\n",
            "|    policy_gradient_loss | -5.31e-07 |\n",
            "|    reward               | 1826318.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.01e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5511470.893794349\n",
            "Sharpe:  1.0372019837699218\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 242        |\n",
            "|    iterations           | 82         |\n",
            "|    time_elapsed         | 691        |\n",
            "|    total_timesteps      | 167936     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0        |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.1      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 1.13e+15   |\n",
            "|    n_updates            | 810        |\n",
            "|    policy_gradient_loss | -5.63e-07  |\n",
            "|    reward               | 1045568.25 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 2.26e+15   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 83        |\n",
            "|    time_elapsed         | 697       |\n",
            "|    total_timesteps      | 169984    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.37e+15  |\n",
            "|    n_updates            | 820       |\n",
            "|    policy_gradient_loss | -5.83e-07 |\n",
            "|    reward               | 4007272.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.68e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5096820.627246381\n",
            "Sharpe:  0.9960059446017204\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 84        |\n",
            "|    time_elapsed         | 707       |\n",
            "|    total_timesteps      | 172032    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.22e+14  |\n",
            "|    n_updates            | 830       |\n",
            "|    policy_gradient_loss | -6.3e-07  |\n",
            "|    reward               | 2842554.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.62e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5700713.174910534\n",
            "Sharpe:  1.051521309844101\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 85        |\n",
            "|    time_elapsed         | 714       |\n",
            "|    total_timesteps      | 174080    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.93e+14  |\n",
            "|    n_updates            | 840       |\n",
            "|    policy_gradient_loss | -5.65e-07 |\n",
            "|    reward               | 2120049.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.69e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5673191.565878282\n",
            "Sharpe:  1.0548569363183702\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 86        |\n",
            "|    time_elapsed         | 722       |\n",
            "|    total_timesteps      | 176128    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.29e+15  |\n",
            "|    n_updates            | 850       |\n",
            "|    policy_gradient_loss | -5.43e-07 |\n",
            "|    reward               | 1273359.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.5e+15   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 87        |\n",
            "|    time_elapsed         | 732       |\n",
            "|    total_timesteps      | 178176    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.36e+15  |\n",
            "|    n_updates            | 860       |\n",
            "|    policy_gradient_loss | -3.08e-07 |\n",
            "|    reward               | 4219243.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.76e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5004680.287517261\n",
            "Sharpe:  0.9833468232781728\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 88        |\n",
            "|    time_elapsed         | 741       |\n",
            "|    total_timesteps      | 180224    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.02e+15  |\n",
            "|    n_updates            | 870       |\n",
            "|    policy_gradient_loss | -5.14e-07 |\n",
            "|    reward               | 3285927.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.04e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5423136.004115538\n",
            "Sharpe:  1.0196112497092953\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 89        |\n",
            "|    time_elapsed         | 750       |\n",
            "|    total_timesteps      | 182272    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.77e+14  |\n",
            "|    n_updates            | 880       |\n",
            "|    policy_gradient_loss | -4.68e-07 |\n",
            "|    reward               | 2062895.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.49e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5523763.673858978\n",
            "Sharpe:  1.036721825616\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 242       |\n",
            "|    iterations           | 90        |\n",
            "|    time_elapsed         | 758       |\n",
            "|    total_timesteps      | 184320    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.16e+15  |\n",
            "|    n_updates            | 890       |\n",
            "|    policy_gradient_loss | -4.46e-07 |\n",
            "|    reward               | 1603986.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.16e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5663349.095994833\n",
            "Sharpe:  1.0489639734195046\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 243        |\n",
            "|    iterations           | 91         |\n",
            "|    time_elapsed         | 765        |\n",
            "|    total_timesteps      | 186368     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0        |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.1      |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 1.2e+15    |\n",
            "|    n_updates            | 900        |\n",
            "|    policy_gradient_loss | -6.15e-07  |\n",
            "|    reward               | 1046540.25 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 2.46e+15   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 92        |\n",
            "|    time_elapsed         | 774       |\n",
            "|    total_timesteps      | 188416    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.34e+15  |\n",
            "|    n_updates            | 910       |\n",
            "|    policy_gradient_loss | -4.54e-07 |\n",
            "|    reward               | 3670019.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.79e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5434059.429435531\n",
            "Sharpe:  1.0314699547709758\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 93        |\n",
            "|    time_elapsed         | 782       |\n",
            "|    total_timesteps      | 190464    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.98e+14  |\n",
            "|    n_updates            | 920       |\n",
            "|    policy_gradient_loss | -6.88e-07 |\n",
            "|    reward               | 2198182.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.39e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4803760.523140498\n",
            "Sharpe:  0.9548330441959377\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 94        |\n",
            "|    time_elapsed         | 789       |\n",
            "|    total_timesteps      | 192512    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 9.23e+14  |\n",
            "|    n_updates            | 930       |\n",
            "|    policy_gradient_loss | -5.08e-07 |\n",
            "|    reward               | 1798620.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.93e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5966473.479442135\n",
            "Sharpe:  1.0699020227718739\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 95        |\n",
            "|    time_elapsed         | 799       |\n",
            "|    total_timesteps      | 194560    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 9.01e+14  |\n",
            "|    n_updates            | 940       |\n",
            "|    policy_gradient_loss | -5.64e-07 |\n",
            "|    reward               | 1098553.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.06e+15  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 96        |\n",
            "|    time_elapsed         | 805       |\n",
            "|    total_timesteps      | 196608    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.38e+15  |\n",
            "|    n_updates            | 950       |\n",
            "|    policy_gradient_loss | -3.43e-07 |\n",
            "|    reward               | 3993128.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.94e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5058580.703108847\n",
            "Sharpe:  0.9884755896922566\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 244       |\n",
            "|    iterations           | 97        |\n",
            "|    time_elapsed         | 813       |\n",
            "|    total_timesteps      | 198656    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.81e+14  |\n",
            "|    n_updates            | 960       |\n",
            "|    policy_gradient_loss | -5.57e-07 |\n",
            "|    reward               | 2697607.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.67e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5393267.872831021\n",
            "Sharpe:  1.0191680988390805\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 243       |\n",
            "|    iterations           | 98        |\n",
            "|    time_elapsed         | 823       |\n",
            "|    total_timesteps      | 200704    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.53e+14  |\n",
            "|    n_updates            | 970       |\n",
            "|    policy_gradient_loss | -4.46e-07 |\n",
            "|    reward               | 2167471.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.6e+15   |\n",
            "---------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_ppo.save('/content/trained_models/trained_ppo.zip')"
      ],
      "metadata": {
        "id": "f1umrzDM4YhN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trading avec A2C\n",
        "\n",
        "Supposons que nous disposions d'un capital initial de 1 000 000 $ au 2020-08-01. Nous utilisons le modèle A2C pour trader les actions du Dow Jones 30."
      ],
      "metadata": {
        "id": "wm8WsZwe-RjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trade = data_split(df,'2020-08-01', '2023-07-31')\n",
        "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)"
      ],
      "metadata": {
        "id": "DQCB0cNy9ew1"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_a2c,\n",
        "                        environment = e_trade_gym)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxmhEtuh_WDo",
        "outputId": "0af7b681-230c-4671-8a0d-f3768d9fbde4"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1337630.4399063664\n",
            "Sharpe:  0.6950432291237063\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_daily_return.to_csv('df_daily_return.csv')\n",
        "df_actions.to_csv('df_actions.csv')"
      ],
      "metadata": {
        "id": "I92tDmlp_99Q"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backtesting"
      ],
      "metadata": {
        "id": "k08wdIlwAGa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyfolio import timeseries\n",
        "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
        "perf_func = timeseries.perf_stats\n",
        "perf_stats_all = perf_func( returns=DRL_strat,\n",
        "                              factor_returns=DRL_strat,\n",
        "                                positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "print(\"==============DRL Strategy Stats===========\")\n",
        "perf_stats_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8-8OX67AFxy",
        "outputId": "b4a6779d-5552-4c92-ec37-c034abfc2c1a"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============DRL Strategy Stats===========\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Annual return          0.102392\n",
              "Cumulative returns     0.337630\n",
              "Annual volatility      0.158302\n",
              "Sharpe ratio           0.695043\n",
              "Calmar ratio           0.453054\n",
              "Stability              0.191665\n",
              "Max drawdown          -0.226004\n",
              "Omega ratio            1.124123\n",
              "Sortino ratio          0.996002\n",
              "Skew                  -0.184815\n",
              "Kurtosis               1.364121\n",
              "Tail ratio             1.033846\n",
              "Daily value at risk   -0.019508\n",
              "Alpha                  0.000000\n",
              "Beta                   1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start = df_daily_return.loc[0,'date'],\n",
        "        end = df_daily_return.loc[len(df_daily_return)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e809dqicAtat",
        "outputId": "8ed17d5a-ab4e-43aa-fcbf-dcde26c0cd72"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Baseline Stats===========\n",
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (751, 8)\n",
            "Annual return          0.098534\n",
            "Cumulative returns     0.323214\n",
            "Annual volatility      0.158543\n",
            "Sharpe ratio           0.672915\n",
            "Calmar ratio           0.449088\n",
            "Stability              0.171560\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            1.119978\n",
            "Sortino ratio          0.959402\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.955792\n",
            "Daily value at risk   -0.019551\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trading avec PPO\n",
        "\n",
        "Supposons que nous disposions d'un capital initial de 1 000 000 $ au 2020-08-01. Nous utilisons le modèle PPO pour trader les actions du Dow Jones 30."
      ],
      "metadata": {
        "id": "UuQ72EwPObvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_ppo,\n",
        "                        environment = e_trade_gym)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPqItn_HObd1",
        "outputId": "9e76b90d-ccc6-4fb3-c043-5429d02164c6"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1378942.5035472454\n",
            "Sharpe:  0.758742627693615\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backtesting"
      ],
      "metadata": {
        "id": "qxaeuSSQOrVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyfolio import timeseries\n",
        "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
        "perf_func = timeseries.perf_stats\n",
        "perf_stats_all = perf_func( returns=DRL_strat,\n",
        "                              factor_returns=DRL_strat,\n",
        "                                positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "print(\"==============DRL Strategy Stats===========\")\n",
        "perf_stats_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouutuYejOtP0",
        "outputId": "2cbf0112-3018-40f5-9838-c41142b4ad35"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============DRL Strategy Stats===========\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Annual return          0.113686\n",
              "Cumulative returns     0.378943\n",
              "Annual volatility      0.158482\n",
              "Sharpe ratio           0.758743\n",
              "Calmar ratio           0.502139\n",
              "Stability              0.238621\n",
              "Max drawdown          -0.226404\n",
              "Omega ratio            1.136589\n",
              "Sortino ratio          1.093967\n",
              "Skew                  -0.129249\n",
              "Kurtosis               1.420060\n",
              "Tail ratio             0.971602\n",
              "Daily value at risk   -0.019490\n",
              "Alpha                  0.000000\n",
              "Beta                   1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start = df_daily_return.loc[0,'date'],\n",
        "        end = df_daily_return.loc[len(df_daily_return)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y97X33wwOyYv",
        "outputId": "af226c9d-6b52-4cb8-e67a-5f6177c9aa0f"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Baseline Stats===========\n",
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (751, 8)\n",
            "Annual return          0.098534\n",
            "Cumulative returns     0.323214\n",
            "Annual volatility      0.158543\n",
            "Sharpe ratio           0.672915\n",
            "Calmar ratio           0.449088\n",
            "Stability              0.171560\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            1.119978\n",
            "Sortino ratio          0.959402\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.955792\n",
            "Daily value at risk   -0.019551\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}